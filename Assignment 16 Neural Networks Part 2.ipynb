{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8280896",
   "metadata": {},
   "source": [
    "# Gas Turbines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "427b0b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2c6c1e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.70</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>114.71</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>111.61</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>111.78</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>110.19</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>110.74</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>111.58</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  114.70  10.605   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  114.72  10.598   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  114.71  10.601   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  114.72  10.606   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  114.72  10.612   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  111.61  10.400   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  111.78  10.433   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  110.19  10.483   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  110.74  10.533   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  111.58  10.583   \n",
       "\n",
       "           CO     NOX  \n",
       "0      3.1547  82.722  \n",
       "1      3.2363  82.776  \n",
       "2      3.2012  82.468  \n",
       "3      3.1923  82.670  \n",
       "4      3.2484  82.311  \n",
       "...       ...     ...  \n",
       "15034  4.5186  79.559  \n",
       "15035  4.8470  79.917  \n",
       "15036  7.9632  90.912  \n",
       "15037  6.2494  93.227  \n",
       "15038  4.9816  92.498  \n",
       "\n",
       "[15039 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('D:/Megha/Desktop/DS assignments/Assignment 16 Neural network/gas_turbines.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5a10df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AT      float64\n",
       "AP      float64\n",
       "AH      float64\n",
       "AFDP    float64\n",
       "GTEP    float64\n",
       "TIT     float64\n",
       "TAT     float64\n",
       "TEY     float64\n",
       "CDP     float64\n",
       "CO      float64\n",
       "NOX     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e33c126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AT      0\n",
       "AP      0\n",
       "AH      0\n",
       "AFDP    0\n",
       "GTEP    0\n",
       "TIT     0\n",
       "TAT     0\n",
       "TEY     0\n",
       "CDP     0\n",
       "CO      0\n",
       "NOX     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69e7ea9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.00000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17.764381</td>\n",
       "      <td>1013.19924</td>\n",
       "      <td>79.124174</td>\n",
       "      <td>4.200294</td>\n",
       "      <td>25.419061</td>\n",
       "      <td>1083.798770</td>\n",
       "      <td>545.396183</td>\n",
       "      <td>134.188464</td>\n",
       "      <td>12.102353</td>\n",
       "      <td>1.972499</td>\n",
       "      <td>68.190934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.574323</td>\n",
       "      <td>6.41076</td>\n",
       "      <td>13.793439</td>\n",
       "      <td>0.760197</td>\n",
       "      <td>4.173916</td>\n",
       "      <td>16.527806</td>\n",
       "      <td>7.866803</td>\n",
       "      <td>15.829717</td>\n",
       "      <td>1.103196</td>\n",
       "      <td>2.222206</td>\n",
       "      <td>10.470586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.522300</td>\n",
       "      <td>985.85000</td>\n",
       "      <td>30.344000</td>\n",
       "      <td>2.087400</td>\n",
       "      <td>17.878000</td>\n",
       "      <td>1000.800000</td>\n",
       "      <td>512.450000</td>\n",
       "      <td>100.170000</td>\n",
       "      <td>9.904400</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>27.765000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.408000</td>\n",
       "      <td>1008.90000</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>3.723900</td>\n",
       "      <td>23.294000</td>\n",
       "      <td>1079.600000</td>\n",
       "      <td>542.170000</td>\n",
       "      <td>127.985000</td>\n",
       "      <td>11.622000</td>\n",
       "      <td>0.858055</td>\n",
       "      <td>61.303500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.186000</td>\n",
       "      <td>1012.80000</td>\n",
       "      <td>82.266000</td>\n",
       "      <td>4.186200</td>\n",
       "      <td>25.082000</td>\n",
       "      <td>1088.700000</td>\n",
       "      <td>549.890000</td>\n",
       "      <td>133.780000</td>\n",
       "      <td>12.025000</td>\n",
       "      <td>1.390200</td>\n",
       "      <td>66.601000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.862500</td>\n",
       "      <td>1016.90000</td>\n",
       "      <td>90.043500</td>\n",
       "      <td>4.550900</td>\n",
       "      <td>27.184000</td>\n",
       "      <td>1096.000000</td>\n",
       "      <td>550.060000</td>\n",
       "      <td>140.895000</td>\n",
       "      <td>12.578000</td>\n",
       "      <td>2.160400</td>\n",
       "      <td>73.935500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34.929000</td>\n",
       "      <td>1034.20000</td>\n",
       "      <td>100.200000</td>\n",
       "      <td>7.610600</td>\n",
       "      <td>37.402000</td>\n",
       "      <td>1100.800000</td>\n",
       "      <td>550.610000</td>\n",
       "      <td>174.610000</td>\n",
       "      <td>15.081000</td>\n",
       "      <td>44.103000</td>\n",
       "      <td>119.890000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AT           AP            AH          AFDP          GTEP  \\\n",
       "count  15039.000000  15039.00000  15039.000000  15039.000000  15039.000000   \n",
       "mean      17.764381   1013.19924     79.124174      4.200294     25.419061   \n",
       "std        7.574323      6.41076     13.793439      0.760197      4.173916   \n",
       "min        0.522300    985.85000     30.344000      2.087400     17.878000   \n",
       "25%       11.408000   1008.90000     69.750000      3.723900     23.294000   \n",
       "50%       18.186000   1012.80000     82.266000      4.186200     25.082000   \n",
       "75%       23.862500   1016.90000     90.043500      4.550900     27.184000   \n",
       "max       34.929000   1034.20000    100.200000      7.610600     37.402000   \n",
       "\n",
       "                TIT           TAT           TEY           CDP            CO  \\\n",
       "count  15039.000000  15039.000000  15039.000000  15039.000000  15039.000000   \n",
       "mean    1083.798770    545.396183    134.188464     12.102353      1.972499   \n",
       "std       16.527806      7.866803     15.829717      1.103196      2.222206   \n",
       "min     1000.800000    512.450000    100.170000      9.904400      0.000388   \n",
       "25%     1079.600000    542.170000    127.985000     11.622000      0.858055   \n",
       "50%     1088.700000    549.890000    133.780000     12.025000      1.390200   \n",
       "75%     1096.000000    550.060000    140.895000     12.578000      2.160400   \n",
       "max     1100.800000    550.610000    174.610000     15.081000     44.103000   \n",
       "\n",
       "                NOX  \n",
       "count  15039.000000  \n",
       "mean      68.190934  \n",
       "std       10.470586  \n",
       "min       27.765000  \n",
       "25%       61.303500  \n",
       "50%       66.601000  \n",
       "75%       73.935500  \n",
       "max      119.890000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6cc6abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [AT, AP, AH, AFDP, GTEP, TIT, TAT, TEY, CDP, CO, NOX]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c15f80c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no duplicated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fcaf12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     CDP      CO  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  10.605  3.1547   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  10.598  3.2363   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  10.601  3.2012   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  10.606  3.1923   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  10.612  3.2484   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  10.400  4.5186   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  10.433  4.8470   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  10.483  7.9632   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  10.533  6.2494   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  10.583  4.9816   \n",
       "\n",
       "          NOX  \n",
       "0      82.722  \n",
       "1      82.776  \n",
       "2      82.468  \n",
       "3      82.670  \n",
       "4      82.311  \n",
       "...       ...  \n",
       "15034  79.559  \n",
       "15035  79.917  \n",
       "15036  90.912  \n",
       "15037  93.227  \n",
       "15038  92.498  \n",
       "\n",
       "[15039 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=df.drop('TEY',axis=1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f03e70bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        114.70\n",
       "1        114.72\n",
       "2        114.71\n",
       "3        114.72\n",
       "4        114.72\n",
       "          ...  \n",
       "15034    111.61\n",
       "15035    111.78\n",
       "15036    110.19\n",
       "15037    110.74\n",
       "15038    111.58\n",
       "Name: TEY, Length: 15039, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=df['TEY']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aaf6994d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   6.8594, 1007.9   ,   96.799 , ...,   10.605 ,    3.1547,\n",
       "          82.722 ],\n",
       "       [   6.785 , 1008.4   ,   97.118 , ...,   10.598 ,    3.2363,\n",
       "          82.776 ],\n",
       "       [   6.8977, 1008.8   ,   95.939 , ...,   10.601 ,    3.2012,\n",
       "          82.468 ],\n",
       "       ...,\n",
       "       [   7.2647, 1006.3   ,   99.496 , ...,   10.483 ,    7.9632,\n",
       "          90.912 ],\n",
       "       [   7.006 , 1006.8   ,   99.008 , ...,   10.533 ,    6.2494,\n",
       "          93.227 ],\n",
       "       [   6.9279, 1007.2   ,   97.533 , ...,   10.583 ,    4.9816,\n",
       "          92.498 ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=x.values\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc34a2a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([114.7 , 114.72, 114.71, ..., 110.19, 110.74, 111.58])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=y.values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "159655b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d5d54a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10527, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4976685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train=scaler.transform(x_train)\n",
    "scaler.fit(x_test)\n",
    "x_test=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ccd8fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10527, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30b50446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b94c49",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c55617fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "148/148 [==============================] - 4s 15ms/step - loss: -6.9539 - accuracy: 0.0000e+00 - val_loss: -91.6654 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/150\n",
      "148/148 [==============================] - 2s 12ms/step - loss: -400.0750 - accuracy: 0.0000e+00 - val_loss: -1027.2087 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/150\n",
      "148/148 [==============================] - 2s 12ms/step - loss: -2756.3044 - accuracy: 0.0000e+00 - val_loss: -5300.7046 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/150\n",
      "148/148 [==============================] - 1s 10ms/step - loss: -9895.9580 - accuracy: 0.0000e+00 - val_loss: -15755.8213 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/150\n",
      "148/148 [==============================] - 2s 12ms/step - loss: -24375.7598 - accuracy: 0.0000e+00 - val_loss: -34319.8242 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/150\n",
      "148/148 [==============================] - 2s 13ms/step - loss: -48686.9844 - accuracy: 0.0000e+00 - val_loss: -65034.6758 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/150\n",
      "148/148 [==============================] - 2s 11ms/step - loss: -87003.4766 - accuracy: 0.0000e+00 - val_loss: -110290.0312 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/150\n",
      "148/148 [==============================] - 2s 12ms/step - loss: -140478.3906 - accuracy: 0.0000e+00 - val_loss: -170938.5938 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/150\n",
      "148/148 [==============================] - 2s 10ms/step - loss: -210235.4688 - accuracy: 0.0000e+00 - val_loss: -248327.1562 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: -296845.0938 - accuracy: 0.0000e+00 - val_loss: -342554.5938 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -401240.2812 - accuracy: 0.0000e+00 - val_loss: -454798.8750 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -524061.6250 - accuracy: 0.0000e+00 - val_loss: -585721.3750 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -666064.0625 - accuracy: 0.0000e+00 - val_loss: -736109.5625 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -828033.5000 - accuracy: 0.0000e+00 - val_loss: -906146.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -1010518.8125 - accuracy: 0.0000e+00 - val_loss: -1096712.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -1213861.6250 - accuracy: 0.0000e+00 - val_loss: -1308580.3750 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -1438554.2500 - accuracy: 0.0000e+00 - val_loss: -1541320.6250 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -1685812.6250 - accuracy: 0.0000e+00 - val_loss: -1796242.3750 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -1955473.3750 - accuracy: 0.0000e+00 - val_loss: -2074481.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -2247540.0000 - accuracy: 0.0000e+00 - val_loss: -2374191.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -2562545.7500 - accuracy: 0.0000e+00 - val_loss: -2697238.2500 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -2901011.5000 - accuracy: 0.0000e+00 - val_loss: -3043441.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -3264021.7500 - accuracy: 0.0000e+00 - val_loss: -3413427.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -3651267.2500 - accuracy: 0.0000e+00 - val_loss: -3809055.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -4063276.5000 - accuracy: 0.0000e+00 - val_loss: -4228791.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -4499363.5000 - accuracy: 0.0000e+00 - val_loss: -4671064.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -4961364.5000 - accuracy: 0.0000e+00 - val_loss: -5140878.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -5448848.5000 - accuracy: 0.0000e+00 - val_loss: -5634845.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -5962564.5000 - accuracy: 0.0000e+00 - val_loss: -6155600.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/150\n",
      "148/148 [==============================] - 1s 4ms/step - loss: -6503375.0000 - accuracy: 0.0000e+00 - val_loss: -6703234.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -7072014.5000 - accuracy: 0.0000e+00 - val_loss: -7278539.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -7667841.5000 - accuracy: 0.0000e+00 - val_loss: -7880120.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/150\n",
      "148/148 [==============================] - 1s 4ms/step - loss: -8290463.5000 - accuracy: 0.0000e+00 - val_loss: -8510645.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/150\n",
      "148/148 [==============================] - 1s 4ms/step - loss: -8941594.0000 - accuracy: 0.0000e+00 - val_loss: -9168059.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: -9620627.0000 - accuracy: 0.0000e+00 - val_loss: -9853065.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/150\n",
      "148/148 [==============================] - 2s 10ms/step - loss: -10329213.0000 - accuracy: 0.0000e+00 - val_loss: -10566734.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/150\n",
      "148/148 [==============================] - 1s 8ms/step - loss: -11066816.0000 - accuracy: 0.0000e+00 - val_loss: -11309580.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/150\n",
      "148/148 [==============================] - 1s 4ms/step - loss: -11834143.0000 - accuracy: 0.0000e+00 - val_loss: -12084029.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/150\n",
      "148/148 [==============================] - 1s 4ms/step - loss: -12633032.0000 - accuracy: 0.0000e+00 - val_loss: -12886096.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/150\n",
      "148/148 [==============================] - 1s 4ms/step - loss: -13461679.0000 - accuracy: 0.0000e+00 - val_loss: -13721284.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/150\n",
      "148/148 [==============================] - 1s 4ms/step - loss: -14321244.0000 - accuracy: 0.0000e+00 - val_loss: -14584850.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/150\n",
      "148/148 [==============================] - 1s 4ms/step - loss: -15211318.0000 - accuracy: 0.0000e+00 - val_loss: -15479338.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/150\n",
      "148/148 [==============================] - 1s 3ms/step - loss: -16132734.0000 - accuracy: 0.0000e+00 - val_loss: -16405966.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/150\n",
      "148/148 [==============================] - 1s 4ms/step - loss: -17087172.0000 - accuracy: 0.0000e+00 - val_loss: -17367546.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/150\n",
      "148/148 [==============================] - 1s 4ms/step - loss: -18071806.0000 - accuracy: 0.0000e+00 - val_loss: -18354464.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/150\n",
      "148/148 [==============================] - 1s 4ms/step - loss: -19091922.0000 - accuracy: 0.0000e+00 - val_loss: -19377442.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/150\n",
      "148/148 [==============================] - 1s 4ms/step - loss: -20143330.0000 - accuracy: 0.0000e+00 - val_loss: -20431504.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/150\n",
      "148/148 [==============================] - 1s 4ms/step - loss: -21228036.0000 - accuracy: 0.0000e+00 - val_loss: -21518890.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/150\n",
      "148/148 [==============================] - 1s 4ms/step - loss: -22347284.0000 - accuracy: 0.0000e+00 - val_loss: -22642714.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 1s 3ms/step - loss: -23499376.0000 - accuracy: 0.0000e+00 - val_loss: -23800322.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/150\n",
      "148/148 [==============================] - 1s 4ms/step - loss: -24686970.0000 - accuracy: 0.0000e+00 - val_loss: -24987730.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/150\n",
      "148/148 [==============================] - 0s 3ms/step - loss: -25907710.0000 - accuracy: 0.0000e+00 - val_loss: -26212242.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -27165220.0000 - accuracy: 0.0000e+00 - val_loss: -27469128.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: -28458260.0000 - accuracy: 0.0000e+00 - val_loss: -28766544.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -29787624.0000 - accuracy: 0.0000e+00 - val_loss: -30096392.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -31154960.0000 - accuracy: 0.0000e+00 - val_loss: -31464632.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: -32558084.0000 - accuracy: 0.0000e+00 - val_loss: -32869712.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/150\n",
      "148/148 [==============================] - 1s 4ms/step - loss: -33999708.0000 - accuracy: 0.0000e+00 - val_loss: -34312232.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -35479088.0000 - accuracy: 0.0000e+00 - val_loss: -35793012.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -36995440.0000 - accuracy: 0.0000e+00 - val_loss: -37311268.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/150\n",
      "148/148 [==============================] - 1s 8ms/step - loss: -38551144.0000 - accuracy: 0.0000e+00 - val_loss: -38867576.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -40144084.0000 - accuracy: 0.0000e+00 - val_loss: -40453640.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -41778216.0000 - accuracy: 0.0000e+00 - val_loss: -42092636.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -43451048.0000 - accuracy: 0.0000e+00 - val_loss: -43761196.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -45162368.0000 - accuracy: 0.0000e+00 - val_loss: -45477524.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -46916960.0000 - accuracy: 0.0000e+00 - val_loss: -47224492.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -48712160.0000 - accuracy: 0.0000e+00 - val_loss: -49017584.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -50547900.0000 - accuracy: 0.0000e+00 - val_loss: -50857612.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -52428836.0000 - accuracy: 0.0000e+00 - val_loss: -52737416.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -54349676.0000 - accuracy: 0.0000e+00 - val_loss: -54649432.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -56315332.0000 - accuracy: 0.0000e+00 - val_loss: -56615500.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -58324388.0000 - accuracy: 0.0000e+00 - val_loss: -58617340.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -60377040.0000 - accuracy: 0.0000e+00 - val_loss: -60670960.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -62471728.0000 - accuracy: 0.0000e+00 - val_loss: -62760232.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -64609904.0000 - accuracy: 0.0000e+00 - val_loss: -64898128.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -66795736.0000 - accuracy: 0.0000e+00 - val_loss: -67077840.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: -69030432.0000 - accuracy: 0.0000e+00 - val_loss: -69305328.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -71305288.0000 - accuracy: 0.0000e+00 - val_loss: -71579064.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -73625672.0000 - accuracy: 0.0000e+00 - val_loss: -73887872.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -75990736.0000 - accuracy: 0.0000e+00 - val_loss: -76243224.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -78402736.0000 - accuracy: 0.0000e+00 - val_loss: -78656016.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -80865088.0000 - accuracy: 0.0000e+00 - val_loss: -81111472.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -83373136.0000 - accuracy: 0.0000e+00 - val_loss: -83610024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -85932552.0000 - accuracy: 0.0000e+00 - val_loss: -86159200.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -88533624.0000 - accuracy: 0.0000e+00 - val_loss: -88757032.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -91186584.0000 - accuracy: 0.0000e+00 - val_loss: -91399920.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -93891688.0000 - accuracy: 0.0000e+00 - val_loss: -94091088.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -96638880.0000 - accuracy: 0.0000e+00 - val_loss: -96832504.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -99436008.0000 - accuracy: 0.0000e+00 - val_loss: -99618736.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -102281504.0000 - accuracy: 0.0000e+00 - val_loss: -102456768.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -105180616.0000 - accuracy: 0.0000e+00 - val_loss: -105340176.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -108127496.0000 - accuracy: 0.0000e+00 - val_loss: -108283792.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: -111127856.0000 - accuracy: 0.0000e+00 - val_loss: -111268768.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -114179064.0000 - accuracy: 0.0000e+00 - val_loss: -114306288.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: -117284672.0000 - accuracy: 0.0000e+00 - val_loss: -117405928.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -120442552.0000 - accuracy: 0.0000e+00 - val_loss: -120533840.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -123654848.0000 - accuracy: 0.0000e+00 - val_loss: -123736000.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 1s 6ms/step - loss: -126921952.0000 - accuracy: 0.0000e+00 - val_loss: -126994496.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -130243336.0000 - accuracy: 0.0000e+00 - val_loss: -130300464.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -133613176.0000 - accuracy: 0.0000e+00 - val_loss: -133652728.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -137037616.0000 - accuracy: 0.0000e+00 - val_loss: -137068576.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -140520720.0000 - accuracy: 0.0000e+00 - val_loss: -140534272.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -144057056.0000 - accuracy: 0.0000e+00 - val_loss: -144057296.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -147651312.0000 - accuracy: 0.0000e+00 - val_loss: -147629872.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -151298304.0000 - accuracy: 0.0000e+00 - val_loss: -151272416.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -155002992.0000 - accuracy: 0.0000e+00 - val_loss: -154942208.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -158766688.0000 - accuracy: 0.0000e+00 - val_loss: -158692640.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -162582688.0000 - accuracy: 0.0000e+00 - val_loss: -162491792.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -166464416.0000 - accuracy: 0.0000e+00 - val_loss: -166339776.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -170398256.0000 - accuracy: 0.0000e+00 - val_loss: -170268480.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -174388048.0000 - accuracy: 0.0000e+00 - val_loss: -174233600.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -178431472.0000 - accuracy: 0.0000e+00 - val_loss: -178272176.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -182540320.0000 - accuracy: 0.0000e+00 - val_loss: -182347440.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -186709888.0000 - accuracy: 0.0000e+00 - val_loss: -186487488.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -190943696.0000 - accuracy: 0.0000e+00 - val_loss: -190713728.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -195234624.0000 - accuracy: 0.0000e+00 - val_loss: -194962384.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -199581264.0000 - accuracy: 0.0000e+00 - val_loss: -199302176.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -203990640.0000 - accuracy: 0.0000e+00 - val_loss: -203688352.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -208461392.0000 - accuracy: 0.0000e+00 - val_loss: -208129792.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -213001168.0000 - accuracy: 0.0000e+00 - val_loss: -212647200.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -217597168.0000 - accuracy: 0.0000e+00 - val_loss: -217208688.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -222256320.0000 - accuracy: 0.0000e+00 - val_loss: -221856192.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -226981120.0000 - accuracy: 0.0000e+00 - val_loss: -226539200.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -231762304.0000 - accuracy: 0.0000e+00 - val_loss: -231303472.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -236604672.0000 - accuracy: 0.0000e+00 - val_loss: -236109024.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -241519600.0000 - accuracy: 0.0000e+00 - val_loss: -241004064.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -246494528.0000 - accuracy: 0.0000e+00 - val_loss: -245938624.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -251538784.0000 - accuracy: 0.0000e+00 - val_loss: -250961328.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -256647696.0000 - accuracy: 0.0000e+00 - val_loss: -256046976.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -261820960.0000 - accuracy: 0.0000e+00 - val_loss: -261173040.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -267055824.0000 - accuracy: 0.0000e+00 - val_loss: -266385152.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -272358112.0000 - accuracy: 0.0000e+00 - val_loss: -271648704.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -277738880.0000 - accuracy: 0.0000e+00 - val_loss: -276994112.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -283181472.0000 - accuracy: 0.0000e+00 - val_loss: -282414560.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -288692960.0000 - accuracy: 0.0000e+00 - val_loss: -287870208.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -294262944.0000 - accuracy: 0.0000e+00 - val_loss: -293403232.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -299913792.0000 - accuracy: 0.0000e+00 - val_loss: -299036032.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -305634720.0000 - accuracy: 0.0000e+00 - val_loss: -304701344.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -311422368.0000 - accuracy: 0.0000e+00 - val_loss: -310466080.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -317274528.0000 - accuracy: 0.0000e+00 - val_loss: -316281888.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -323187296.0000 - accuracy: 0.0000e+00 - val_loss: -322155296.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -329170016.0000 - accuracy: 0.0000e+00 - val_loss: -328094752.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -335235136.0000 - accuracy: 0.0000e+00 - val_loss: -334115616.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -341363040.0000 - accuracy: 0.0000e+00 - val_loss: -340207488.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: -347558944.0000 - accuracy: 0.0000e+00 - val_loss: -346372512.0000 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -353828224.0000 - accuracy: 0.0000e+00 - val_loss: -352611776.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -360182912.0000 - accuracy: 0.0000e+00 - val_loss: -358908960.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -366613344.0000 - accuracy: 0.0000e+00 - val_loss: -365288256.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -373111776.0000 - accuracy: 0.0000e+00 - val_loss: -371736192.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: -379670016.0000 - accuracy: 0.0000e+00 - val_loss: -378262912.0000 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a91e60b8e0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=10, activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(x_train,y_train, validation_split=0.3, epochs=150, batch_size=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2e61d3",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "980976de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "148/148 [==============================] - 3s 10ms/step - loss: 18110.4375 - cosine_proximity: 1.0000 - val_loss: 17976.2227 - val_cosine_proximity: 1.0000\n",
      "Epoch 2/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 18046.0352 - cosine_proximity: 1.0000 - val_loss: 17928.0918 - val_cosine_proximity: 1.0000\n",
      "Epoch 3/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18018.2734 - cosine_proximity: 1.0000 - val_loss: 17914.4180 - val_cosine_proximity: 1.0000\n",
      "Epoch 4/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18010.1152 - cosine_proximity: 1.0000 - val_loss: 17910.5332 - val_cosine_proximity: 1.0000\n",
      "Epoch 5/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 18007.9297 - cosine_proximity: 1.0000 - val_loss: 17909.3906 - val_cosine_proximity: 1.0000\n",
      "Epoch 6/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18007.1855 - cosine_proximity: 1.0000 - val_loss: 17908.9199 - val_cosine_proximity: 1.0000\n",
      "Epoch 7/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.8398 - cosine_proximity: 1.0000 - val_loss: 17908.6816 - val_cosine_proximity: 1.0000\n",
      "Epoch 8/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.6660 - cosine_proximity: 1.0000 - val_loss: 17908.5488 - val_cosine_proximity: 1.0000\n",
      "Epoch 9/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.5508 - cosine_proximity: 1.0000 - val_loss: 17908.4648 - val_cosine_proximity: 1.0000\n",
      "Epoch 10/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.4805 - cosine_proximity: 1.0000 - val_loss: 17908.3965 - val_cosine_proximity: 1.0000\n",
      "Epoch 11/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.4414 - cosine_proximity: 1.0000 - val_loss: 17908.3613 - val_cosine_proximity: 1.0000\n",
      "Epoch 12/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.4004 - cosine_proximity: 1.0000 - val_loss: 17908.3320 - val_cosine_proximity: 1.0000\n",
      "Epoch 13/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 18006.3750 - cosine_proximity: 1.0000 - val_loss: 17908.3105 - val_cosine_proximity: 1.0000\n",
      "Epoch 14/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 18006.3555 - cosine_proximity: 1.0000 - val_loss: 17908.2969 - val_cosine_proximity: 1.0000\n",
      "Epoch 15/150\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 18006.3379 - cosine_proximity: 1.0000 - val_loss: 17908.2832 - val_cosine_proximity: 1.0000\n",
      "Epoch 16/150\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 18006.3301 - cosine_proximity: 1.0000 - val_loss: 17908.2715 - val_cosine_proximity: 1.0000\n",
      "Epoch 17/150\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 18006.3203 - cosine_proximity: 1.0000 - val_loss: 17908.2637 - val_cosine_proximity: 1.0000\n",
      "Epoch 18/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 18008.7715 - cosine_proximity: 1.00 - 1s 4ms/step - loss: 18006.3145 - cosine_proximity: 1.0000 - val_loss: 17908.2578 - val_cosine_proximity: 1.0000\n",
      "Epoch 19/150\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 18006.3086 - cosine_proximity: 1.0000 - val_loss: 17908.2500 - val_cosine_proximity: 1.0000\n",
      "Epoch 20/150\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 18006.3047 - cosine_proximity: 1.0000 - val_loss: 17908.2461 - val_cosine_proximity: 1.0000\n",
      "Epoch 21/150\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 18006.2969 - cosine_proximity: 1.0000 - val_loss: 17908.2422 - val_cosine_proximity: 1.0000\n",
      "Epoch 22/150\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 18006.2891 - cosine_proximity: 1.0000 - val_loss: 17908.2402 - val_cosine_proximity: 1.0000\n",
      "Epoch 23/150\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 18006.2891 - cosine_proximity: 1.0000 - val_loss: 17908.2363 - val_cosine_proximity: 1.0000\n",
      "Epoch 24/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2891 - cosine_proximity: 1.0000 - val_loss: 17908.2344 - val_cosine_proximity: 1.0000\n",
      "Epoch 25/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2871 - cosine_proximity: 1.0000 - val_loss: 17908.2324 - val_cosine_proximity: 1.0000\n",
      "Epoch 26/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2871 - cosine_proximity: 1.0000 - val_loss: 17908.2324 - val_cosine_proximity: 1.0000\n",
      "Epoch 27/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2852 - cosine_proximity: 1.0000 - val_loss: 17908.2305 - val_cosine_proximity: 1.0000\n",
      "Epoch 28/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2832 - cosine_proximity: 1.0000 - val_loss: 17908.2305 - val_cosine_proximity: 1.0000\n",
      "Epoch 29/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 18006.2773 - cosine_proximity: 1.0000 - val_loss: 17908.2285 - val_cosine_proximity: 1.0000\n",
      "Epoch 30/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 18006.2773 - cosine_proximity: 1.0000 - val_loss: 17908.2285 - val_cosine_proximity: 1.0000\n",
      "Epoch 31/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2773 - cosine_proximity: 1.0000 - val_loss: 17908.2266 - val_cosine_proximity: 1.0000\n",
      "Epoch 32/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2754 - cosine_proximity: 1.0000 - val_loss: 17908.2266 - val_cosine_proximity: 1.0000\n",
      "Epoch 33/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2754 - cosine_proximity: 1.0000 - val_loss: 17908.2246 - val_cosine_proximity: 1.0000\n",
      "Epoch 34/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2773 - cosine_proximity: 1.0000 - val_loss: 17908.2246 - val_cosine_proximity: 1.0000\n",
      "Epoch 35/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2754 - cosine_proximity: 1.0000 - val_loss: 17908.2246 - val_cosine_proximity: 1.0000\n",
      "Epoch 36/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2812 - cosine_proximity: 1.0000 - val_loss: 17908.2246 - val_cosine_proximity: 1.0000\n",
      "Epoch 37/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2754 - cosine_proximity: 1.0000 - val_loss: 17908.2227 - val_cosine_proximity: 1.0000\n",
      "Epoch 38/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 18006.2754 - cosine_proximity: 1.0000 - val_loss: 17908.2227 - val_cosine_proximity: 1.0000\n",
      "Epoch 39/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 18006.2734 - cosine_proximity: 1.0000 - val_loss: 17908.2227 - val_cosine_proximity: 1.0000\n",
      "Epoch 40/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2773 - cosine_proximity: 1.0000 - val_loss: 17908.2227 - val_cosine_proximity: 1.0000\n",
      "Epoch 41/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2734 - cosine_proximity: 1.0000 - val_loss: 17908.2227 - val_cosine_proximity: 1.0000\n",
      "Epoch 42/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 18006.2715 - cosine_proximity: 1.0000 - val_loss: 17908.2227 - val_cosine_proximity: 1.0000\n",
      "Epoch 43/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2695 - cosine_proximity: 1.0000 - val_loss: 17908.2207 - val_cosine_proximity: 1.0000\n",
      "Epoch 44/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 18006.2676 - cosine_proximity: 1.0000 - val_loss: 17908.2207 - val_cosine_proximity: 1.0000\n",
      "Epoch 45/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 18006.2715 - cosine_proximity: 1.0000 - val_loss: 17908.2207 - val_cosine_proximity: 1.0000\n",
      "Epoch 46/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 18006.2734 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 47/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2754 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 48/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 18006.2676 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 49/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2734 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 50/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 18006.2695 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 51/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2695 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 52/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 18006.2773 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 53/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2637 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 54/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 18006.2715 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 55/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2695 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 56/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2695 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 57/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 18006.2695 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 58/150\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 18006.2695 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 59/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 18006.2754 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 60/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2715 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 61/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2676 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 62/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 18006.2695 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 63/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 18006.2734 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 64/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2715 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 65/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2695 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 66/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 18006.2734 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 67/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2773 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 68/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2656 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 69/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 18006.2695 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 70/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2695 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 71/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2715 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 72/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2734 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 73/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2754 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 74/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2734 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 75/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2754 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 76/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2656 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 77/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2676 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 78/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2734 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 79/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 18006.2676 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 80/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 18006.2715 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 81/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2676 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 82/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2734 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 83/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2676 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 84/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 18006.2695 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 85/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2676 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 86/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 18006.2715 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 87/150\n",
      "148/148 [==============================] - 1s 9ms/step - loss: 18006.2637 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 88/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 18006.2656 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 89/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2676 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 90/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2695 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 91/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 18006.2695 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 92/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 18006.2676 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 93/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 18006.2734 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 94/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 18006.2715 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 95/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2695 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 96/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2676 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 97/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2656 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2676 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 99/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2676 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 100/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2676 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 101/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 18006.2656 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 102/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 18006.2734 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 103/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2695 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 104/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2695 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 105/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2637 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 106/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2695 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 107/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2715 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 108/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 18006.2676 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 109/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2734 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 110/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 18006.2656 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 111/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2715 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 112/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2715 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 113/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 18006.2656 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 114/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 18006.2695 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 115/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2676 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 116/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 18006.2734 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 117/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2754 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 118/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 18006.2695 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 119/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2656 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 120/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2695 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 121/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2676 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 122/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2695 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 123/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2676 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 124/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2676 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 125/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2734 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 126/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2734 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 127/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2715 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 128/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2754 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 129/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2676 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 130/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2754 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 131/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2676 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 132/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2676 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 133/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2656 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 134/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2734 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 135/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2656 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 136/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2734 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 137/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2637 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 138/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2695 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 139/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2656 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 140/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2695 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 141/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2754 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 142/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2676 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 143/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2676 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 144/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2695 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 145/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2676 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 146/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 1s 5ms/step - loss: 18006.2637 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 147/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2695 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 148/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 18006.2715 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 149/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2676 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n",
      "Epoch 150/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 18006.2695 - cosine_proximity: 1.0000 - val_loss: 17908.2188 - val_cosine_proximity: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a9244a9670>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=10, activation='softmax'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['cosine_proximity'])\n",
    "model.fit(x_train,y_train, validation_split=0.3, epochs=150, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f9aa67",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5c4f8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "148/148 [==============================] - 2s 8ms/step - loss: 18065.4082 - mean_squared_error: 18065.4082 - val_loss: 17847.3027 - val_mean_squared_error: 17847.3027\n",
      "Epoch 2/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 17822.8633 - mean_squared_error: 17822.8633 - val_loss: 17597.5156 - val_mean_squared_error: 17597.5156\n",
      "Epoch 3/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 17562.3496 - mean_squared_error: 17562.3496 - val_loss: 17327.3789 - val_mean_squared_error: 17327.3789\n",
      "Epoch 4/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 17282.7559 - mean_squared_error: 17282.7559 - val_loss: 17038.5410 - val_mean_squared_error: 17038.5410\n",
      "Epoch 5/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 16982.0352 - mean_squared_error: 16982.0352 - val_loss: 16728.2539 - val_mean_squared_error: 16728.2539\n",
      "Epoch 6/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 16661.1816 - mean_squared_error: 16661.1816 - val_loss: 16399.9043 - val_mean_squared_error: 16399.9043\n",
      "Epoch 7/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 16327.2832 - mean_squared_error: 16327.2842 - val_loss: 16063.2607 - val_mean_squared_error: 16063.2607\n",
      "Epoch 8/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 15985.0840 - mean_squared_error: 15985.0840 - val_loss: 15718.4072 - val_mean_squared_error: 15718.4072\n",
      "Epoch 9/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 15638.4248 - mean_squared_error: 15638.4248 - val_loss: 15370.7627 - val_mean_squared_error: 15370.7627\n",
      "Epoch 10/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 15288.5127 - mean_squared_error: 15288.5127 - val_loss: 15021.6377 - val_mean_squared_error: 15021.6377\n",
      "Epoch 11/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 14940.0381 - mean_squared_error: 14940.0381 - val_loss: 14676.5645 - val_mean_squared_error: 14676.5645\n",
      "Epoch 12/150\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 14595.9355 - mean_squared_error: 14595.9355 - val_loss: 14335.6621 - val_mean_squared_error: 14335.6621\n",
      "Epoch 13/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 14255.4209 - mean_squared_error: 14255.4209 - val_loss: 13998.8096 - val_mean_squared_error: 13998.8096\n",
      "Epoch 14/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 13920.0488 - mean_squared_error: 13920.0488 - val_loss: 13665.9736 - val_mean_squared_error: 13665.9736\n",
      "Epoch 15/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 13590.4385 - mean_squared_error: 13590.4385 - val_loss: 13342.6172 - val_mean_squared_error: 13342.6172\n",
      "Epoch 16/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 13269.3115 - mean_squared_error: 13269.3115 - val_loss: 13026.5840 - val_mean_squared_error: 13026.5840\n",
      "Epoch 17/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 12956.3320 - mean_squared_error: 12956.3320 - val_loss: 12719.2354 - val_mean_squared_error: 12719.2354\n",
      "Epoch 18/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 12651.4385 - mean_squared_error: 12651.4385 - val_loss: 12418.5693 - val_mean_squared_error: 12418.5693\n",
      "Epoch 19/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 12352.5430 - mean_squared_error: 12352.5430 - val_loss: 12123.3584 - val_mean_squared_error: 12123.3584\n",
      "Epoch 20/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 12059.2871 - mean_squared_error: 12059.2871 - val_loss: 11833.3066 - val_mean_squared_error: 11833.3066\n",
      "Epoch 21/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 11771.2158 - mean_squared_error: 11771.2158 - val_loss: 11548.9062 - val_mean_squared_error: 11548.9062\n",
      "Epoch 22/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 11488.2168 - mean_squared_error: 11488.2168 - val_loss: 11269.4395 - val_mean_squared_error: 11269.4395\n",
      "Epoch 23/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 11210.4492 - mean_squared_error: 11210.4492 - val_loss: 10994.7646 - val_mean_squared_error: 10994.7646\n",
      "Epoch 24/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 10936.0352 - mean_squared_error: 10936.0352 - val_loss: 10723.4697 - val_mean_squared_error: 10723.4697\n",
      "Epoch 25/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 10666.1289 - mean_squared_error: 10666.1289 - val_loss: 10456.4746 - val_mean_squared_error: 10456.4746\n",
      "Epoch 26/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 10401.4170 - mean_squared_error: 10401.4170 - val_loss: 10196.0039 - val_mean_squared_error: 10196.0039\n",
      "Epoch 27/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 10140.8896 - mean_squared_error: 10140.8896 - val_loss: 9938.0498 - val_mean_squared_error: 9938.0498\n",
      "Epoch 28/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 9885.0391 - mean_squared_error: 9885.0391 - val_loss: 9685.4863 - val_mean_squared_error: 9685.4863\n",
      "Epoch 29/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 9633.0225 - mean_squared_error: 9633.0225 - val_loss: 9436.7646 - val_mean_squared_error: 9436.7646\n",
      "Epoch 30/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 9384.3193 - mean_squared_error: 9384.3193 - val_loss: 9191.0127 - val_mean_squared_error: 9191.0127\n",
      "Epoch 31/150\n",
      "148/148 [==============================] - 1s 8ms/step - loss: 9139.4346 - mean_squared_error: 9139.4346 - val_loss: 8948.6377 - val_mean_squared_error: 8948.6377\n",
      "Epoch 32/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 8898.0059 - mean_squared_error: 8898.0059 - val_loss: 8709.4854 - val_mean_squared_error: 8709.4844\n",
      "Epoch 33/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 8659.9131 - mean_squared_error: 8659.9131 - val_loss: 8475.1514 - val_mean_squared_error: 8475.1523\n",
      "Epoch 34/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 8427.0479 - mean_squared_error: 8427.0479 - val_loss: 8244.6523 - val_mean_squared_error: 8244.6523\n",
      "Epoch 35/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 8197.3877 - mean_squared_error: 8197.3877 - val_loss: 8018.9814 - val_mean_squared_error: 8018.9814\n",
      "Epoch 36/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7972.1206 - mean_squared_error: 7972.1206 - val_loss: 7796.1304 - val_mean_squared_error: 7796.1304\n",
      "Epoch 37/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7750.1558 - mean_squared_error: 7750.1558 - val_loss: 7574.8125 - val_mean_squared_error: 7574.8125\n",
      "Epoch 38/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7529.0327 - mean_squared_error: 7529.0327 - val_loss: 7356.5869 - val_mean_squared_error: 7356.5869\n",
      "Epoch 39/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7311.9707 - mean_squared_error: 7311.9707 - val_loss: 7142.5229 - val_mean_squared_error: 7142.5229\n",
      "Epoch 40/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 7097.9722 - mean_squared_error: 7097.9722 - val_loss: 6931.6250 - val_mean_squared_error: 6931.6250\n",
      "Epoch 41/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 6889.7324 - mean_squared_error: 6889.7324 - val_loss: 6726.3604 - val_mean_squared_error: 6726.3604\n",
      "Epoch 42/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 6683.2798 - mean_squared_error: 6683.2798 - val_loss: 6521.3594 - val_mean_squared_error: 6521.3594\n",
      "Epoch 43/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 6479.2051 - mean_squared_error: 6479.2051 - val_loss: 6320.2007 - val_mean_squared_error: 6320.2007\n",
      "Epoch 44/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 6278.4482 - mean_squared_error: 6278.4482 - val_loss: 6122.5479 - val_mean_squared_error: 6122.5479\n",
      "Epoch 45/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 6083.3550 - mean_squared_error: 6083.3550 - val_loss: 5930.7798 - val_mean_squared_error: 5930.7798\n",
      "Epoch 46/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 5890.6343 - mean_squared_error: 5890.6343 - val_loss: 5739.3931 - val_mean_squared_error: 5739.3931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 5700.5981 - mean_squared_error: 5700.5981 - val_loss: 5552.7612 - val_mean_squared_error: 5552.7612\n",
      "Epoch 48/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 5514.8066 - mean_squared_error: 5514.8066 - val_loss: 5369.5044 - val_mean_squared_error: 5369.5049\n",
      "Epoch 49/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 5333.0425 - mean_squared_error: 5333.0425 - val_loss: 5191.1743 - val_mean_squared_error: 5191.1743\n",
      "Epoch 50/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 5155.5410 - mean_squared_error: 5155.5410 - val_loss: 5016.6489 - val_mean_squared_error: 5016.6489\n",
      "Epoch 51/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4981.3706 - mean_squared_error: 4981.3706 - val_loss: 4844.5630 - val_mean_squared_error: 4844.5630\n",
      "Epoch 52/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 4809.8120 - mean_squared_error: 4809.8115 - val_loss: 4674.9097 - val_mean_squared_error: 4674.9097\n",
      "Epoch 53/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 4639.1543 - mean_squared_error: 4639.1543 - val_loss: 4507.1748 - val_mean_squared_error: 4507.1748\n",
      "Epoch 54/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4473.1279 - mean_squared_error: 4473.1279 - val_loss: 4343.1416 - val_mean_squared_error: 4343.1416\n",
      "Epoch 55/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4309.3667 - mean_squared_error: 4309.3662 - val_loss: 4182.3384 - val_mean_squared_error: 4182.3384\n",
      "Epoch 56/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4150.2202 - mean_squared_error: 4150.2202 - val_loss: 4026.4204 - val_mean_squared_error: 4026.4204\n",
      "Epoch 57/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 3994.8162 - mean_squared_error: 3994.8162 - val_loss: 3874.4934 - val_mean_squared_error: 3874.4932\n",
      "Epoch 58/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 3844.6501 - mean_squared_error: 3844.6501 - val_loss: 3726.8450 - val_mean_squared_error: 3726.8450\n",
      "Epoch 59/150\n",
      "148/148 [==============================] - 1s 8ms/step - loss: 3697.7014 - mean_squared_error: 3697.7014 - val_loss: 3582.1206 - val_mean_squared_error: 3582.1206\n",
      "Epoch 60/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 3554.0718 - mean_squared_error: 3554.0718 - val_loss: 3440.9468 - val_mean_squared_error: 3440.9468\n",
      "Epoch 61/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 3412.1318 - mean_squared_error: 3412.1318 - val_loss: 3301.1096 - val_mean_squared_error: 3301.1096\n",
      "Epoch 62/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 3273.0430 - mean_squared_error: 3273.0430 - val_loss: 3164.1621 - val_mean_squared_error: 3164.1621\n",
      "Epoch 63/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 3136.3301 - mean_squared_error: 3136.3301 - val_loss: 3031.3604 - val_mean_squared_error: 3031.3604\n",
      "Epoch 64/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 3004.6855 - mean_squared_error: 3004.6855 - val_loss: 2901.2910 - val_mean_squared_error: 2901.2910\n",
      "Epoch 65/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 2875.6936 - mean_squared_error: 2875.6936 - val_loss: 2775.0808 - val_mean_squared_error: 2775.0808\n",
      "Epoch 66/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 2750.0088 - mean_squared_error: 2750.0088 - val_loss: 2652.9719 - val_mean_squared_error: 2652.9719\n",
      "Epoch 67/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 2629.9387 - mean_squared_error: 2629.9387 - val_loss: 2536.0920 - val_mean_squared_error: 2536.0920\n",
      "Epoch 68/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 2512.1084 - mean_squared_error: 2512.1084 - val_loss: 2418.9309 - val_mean_squared_error: 2418.9309\n",
      "Epoch 69/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 2396.6562 - mean_squared_error: 2396.6562 - val_loss: 2307.5337 - val_mean_squared_error: 2307.5337\n",
      "Epoch 70/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 2284.7322 - mean_squared_error: 2284.7319 - val_loss: 2197.3894 - val_mean_squared_error: 2197.3894\n",
      "Epoch 71/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 2175.5469 - mean_squared_error: 2175.5469 - val_loss: 2090.4587 - val_mean_squared_error: 2090.4587\n",
      "Epoch 72/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 2069.9609 - mean_squared_error: 2069.9609 - val_loss: 1987.4692 - val_mean_squared_error: 1987.4692\n",
      "Epoch 73/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1967.6660 - mean_squared_error: 1967.6660 - val_loss: 1888.5956 - val_mean_squared_error: 1888.5956\n",
      "Epoch 74/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 1869.5364 - mean_squared_error: 1869.5364 - val_loss: 1792.4652 - val_mean_squared_error: 1792.4652\n",
      "Epoch 75/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 1773.3275 - mean_squared_error: 1773.3275 - val_loss: 1698.4391 - val_mean_squared_error: 1698.4391\n",
      "Epoch 76/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 1681.7550 - mean_squared_error: 1681.7550 - val_loss: 1610.3221 - val_mean_squared_error: 1610.3221\n",
      "Epoch 77/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1592.3077 - mean_squared_error: 1592.3077 - val_loss: 1522.6826 - val_mean_squared_error: 1522.6826\n",
      "Epoch 78/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1506.9017 - mean_squared_error: 1506.9017 - val_loss: 1440.0732 - val_mean_squared_error: 1440.0732\n",
      "Epoch 79/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1424.6091 - mean_squared_error: 1424.6091 - val_loss: 1361.2604 - val_mean_squared_error: 1361.2604\n",
      "Epoch 80/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1346.2750 - mean_squared_error: 1346.2750 - val_loss: 1284.3088 - val_mean_squared_error: 1284.3088\n",
      "Epoch 81/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 1270.0919 - mean_squared_error: 1270.0919 - val_loss: 1210.2435 - val_mean_squared_error: 1210.2435\n",
      "Epoch 82/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1196.7809 - mean_squared_error: 1196.7809 - val_loss: 1139.6934 - val_mean_squared_error: 1139.6934\n",
      "Epoch 83/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1126.9719 - mean_squared_error: 1126.9719 - val_loss: 1072.6268 - val_mean_squared_error: 1072.6268\n",
      "Epoch 84/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1059.6193 - mean_squared_error: 1059.6193 - val_loss: 1007.4008 - val_mean_squared_error: 1007.4007\n",
      "Epoch 85/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 995.0322 - mean_squared_error: 995.0322 - val_loss: 944.3322 - val_mean_squared_error: 944.3322\n",
      "Epoch 86/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 933.8179 - mean_squared_error: 933.8179 - val_loss: 887.6788 - val_mean_squared_error: 887.6788\n",
      "Epoch 87/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 877.7534 - mean_squared_error: 877.7534 - val_loss: 833.1790 - val_mean_squared_error: 833.1790\n",
      "Epoch 88/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 823.0580 - mean_squared_error: 823.0580 - val_loss: 779.9448 - val_mean_squared_error: 779.9448\n",
      "Epoch 89/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 770.8210 - mean_squared_error: 770.8210 - val_loss: 730.3898 - val_mean_squared_error: 730.3898\n",
      "Epoch 90/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 721.5706 - mean_squared_error: 721.5706 - val_loss: 682.5305 - val_mean_squared_error: 682.5305\n",
      "Epoch 91/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 674.9078 - mean_squared_error: 674.9078 - val_loss: 639.4689 - val_mean_squared_error: 639.4689\n",
      "Epoch 92/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 633.0214 - mean_squared_error: 633.0214 - val_loss: 600.5638 - val_mean_squared_error: 600.5638\n",
      "Epoch 93/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 594.2515 - mean_squared_error: 594.2515 - val_loss: 563.3226 - val_mean_squared_error: 563.3226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 557.2153 - mean_squared_error: 557.2153 - val_loss: 528.1923 - val_mean_squared_error: 528.1923\n",
      "Epoch 95/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 522.8384 - mean_squared_error: 522.8384 - val_loss: 496.2392 - val_mean_squared_error: 496.2392\n",
      "Epoch 96/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 492.2656 - mean_squared_error: 492.2656 - val_loss: 467.6091 - val_mean_squared_error: 467.6091\n",
      "Epoch 97/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 463.3001 - mean_squared_error: 463.3001 - val_loss: 440.2640 - val_mean_squared_error: 440.2640\n",
      "Epoch 98/150\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 436.4038 - mean_squared_error: 436.4038 - val_loss: 415.0536 - val_mean_squared_error: 415.0536\n",
      "Epoch 99/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 411.2292 - mean_squared_error: 411.2292 - val_loss: 391.8546 - val_mean_squared_error: 391.8546\n",
      "Epoch 100/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 388.1823 - mean_squared_error: 388.1823 - val_loss: 370.0193 - val_mean_squared_error: 370.0193\n",
      "Epoch 101/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 366.9976 - mean_squared_error: 366.9976 - val_loss: 351.0298 - val_mean_squared_error: 351.0298\n",
      "Epoch 102/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 349.5728 - mean_squared_error: 349.5728 - val_loss: 336.3086 - val_mean_squared_error: 336.3086\n",
      "Epoch 103/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 334.5513 - mean_squared_error: 334.5513 - val_loss: 322.0614 - val_mean_squared_error: 322.0614\n",
      "Epoch 104/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 320.4450 - mean_squared_error: 320.4450 - val_loss: 309.5648 - val_mean_squared_error: 309.5648\n",
      "Epoch 105/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 308.0233 - mean_squared_error: 308.0233 - val_loss: 298.2496 - val_mean_squared_error: 298.2496\n",
      "Epoch 106/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 297.8211 - mean_squared_error: 297.8211 - val_loss: 290.1935 - val_mean_squared_error: 290.1935\n",
      "Epoch 107/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 289.5377 - mean_squared_error: 289.5377 - val_loss: 282.5713 - val_mean_squared_error: 282.5713\n",
      "Epoch 108/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 281.7370 - mean_squared_error: 281.7370 - val_loss: 275.5736 - val_mean_squared_error: 275.5736\n",
      "Epoch 109/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 274.6764 - mean_squared_error: 274.6764 - val_loss: 269.4815 - val_mean_squared_error: 269.4815\n",
      "Epoch 110/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 268.6884 - mean_squared_error: 268.6884 - val_loss: 264.6606 - val_mean_squared_error: 264.6606\n",
      "Epoch 111/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 264.1401 - mean_squared_error: 264.1401 - val_loss: 261.1038 - val_mean_squared_error: 261.1038\n",
      "Epoch 112/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 260.5438 - mean_squared_error: 260.5438 - val_loss: 258.2522 - val_mean_squared_error: 258.2522\n",
      "Epoch 113/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 257.7570 - mean_squared_error: 257.7570 - val_loss: 256.1105 - val_mean_squared_error: 256.1105\n",
      "Epoch 114/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 255.5475 - mean_squared_error: 255.5475 - val_loss: 254.5157 - val_mean_squared_error: 254.5157\n",
      "Epoch 115/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 253.8498 - mean_squared_error: 253.8498 - val_loss: 253.3366 - val_mean_squared_error: 253.3366\n",
      "Epoch 116/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 252.6119 - mean_squared_error: 252.6119 - val_loss: 252.5148 - val_mean_squared_error: 252.5148\n",
      "Epoch 117/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 251.7109 - mean_squared_error: 251.7109 - val_loss: 251.9262 - val_mean_squared_error: 251.9262\n",
      "Epoch 118/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 251.0677 - mean_squared_error: 251.0677 - val_loss: 251.5791 - val_mean_squared_error: 251.5791\n",
      "Epoch 119/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 250.6224 - mean_squared_error: 250.6224 - val_loss: 251.3827 - val_mean_squared_error: 251.3827\n",
      "Epoch 120/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 250.3449 - mean_squared_error: 250.3449 - val_loss: 251.2826 - val_mean_squared_error: 251.2826\n",
      "Epoch 121/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 250.1609 - mean_squared_error: 250.1609 - val_loss: 251.2230 - val_mean_squared_error: 251.2230\n",
      "Epoch 122/150\n",
      "148/148 [==============================] - ETA: 0s - loss: 250.4898 - mean_squared_error: 250.48 - 1s 5ms/step - loss: 250.0350 - mean_squared_error: 250.0350 - val_loss: 251.2004 - val_mean_squared_error: 251.2004\n",
      "Epoch 123/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 249.9635 - mean_squared_error: 249.9635 - val_loss: 251.1981 - val_mean_squared_error: 251.1981\n",
      "Epoch 124/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 249.9115 - mean_squared_error: 249.9114 - val_loss: 251.2014 - val_mean_squared_error: 251.2014\n",
      "Epoch 125/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 249.8721 - mean_squared_error: 249.8721 - val_loss: 251.2032 - val_mean_squared_error: 251.2032\n",
      "Epoch 126/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 249.8429 - mean_squared_error: 249.8429 - val_loss: 251.2083 - val_mean_squared_error: 251.2083\n",
      "Epoch 127/150\n",
      "148/148 [==============================] - 1s 9ms/step - loss: 249.8184 - mean_squared_error: 249.8184 - val_loss: 251.2047 - val_mean_squared_error: 251.2048\n",
      "Epoch 128/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 249.7975 - mean_squared_error: 249.7975 - val_loss: 251.2021 - val_mean_squared_error: 251.2021\n",
      "Epoch 129/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 249.7621 - mean_squared_error: 249.7621 - val_loss: 251.1878 - val_mean_squared_error: 251.1879\n",
      "Epoch 130/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 249.7249 - mean_squared_error: 249.7249 - val_loss: 251.1641 - val_mean_squared_error: 251.1641\n",
      "Epoch 131/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 249.6666 - mean_squared_error: 249.6666 - val_loss: 251.0967 - val_mean_squared_error: 251.0967\n",
      "Epoch 132/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 249.5820 - mean_squared_error: 249.5820 - val_loss: 250.9981 - val_mean_squared_error: 250.9981\n",
      "Epoch 133/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 249.4353 - mean_squared_error: 249.4353 - val_loss: 250.8288 - val_mean_squared_error: 250.8288\n",
      "Epoch 134/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 249.2097 - mean_squared_error: 249.2097 - val_loss: 250.5403 - val_mean_squared_error: 250.5403\n",
      "Epoch 135/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 248.8544 - mean_squared_error: 248.8544 - val_loss: 250.0768 - val_mean_squared_error: 250.0768\n",
      "Epoch 136/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 248.3743 - mean_squared_error: 248.3743 - val_loss: 249.4690 - val_mean_squared_error: 249.4690\n",
      "Epoch 137/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 247.7482 - mean_squared_error: 247.7482 - val_loss: 248.7356 - val_mean_squared_error: 248.7356\n",
      "Epoch 138/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 247.0130 - mean_squared_error: 247.0130 - val_loss: 247.8624 - val_mean_squared_error: 247.8624\n",
      "Epoch 139/150\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 246.0804 - mean_squared_error: 246.0804 - val_loss: 246.8876 - val_mean_squared_error: 246.8876\n",
      "Epoch 140/150\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 245.0824 - mean_squared_error: 245.0824 - val_loss: 245.7570 - val_mean_squared_error: 245.7570\n",
      "Epoch 141/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 1s 7ms/step - loss: 243.7878 - mean_squared_error: 243.7878 - val_loss: 244.2780 - val_mean_squared_error: 244.2780\n",
      "Epoch 142/150\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 242.1928 - mean_squared_error: 242.1928 - val_loss: 242.5439 - val_mean_squared_error: 242.5439\n",
      "Epoch 143/150\n",
      "148/148 [==============================] - 1s 8ms/step - loss: 240.3732 - mean_squared_error: 240.3732 - val_loss: 240.4440 - val_mean_squared_error: 240.4440\n",
      "Epoch 144/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 238.0406 - mean_squared_error: 238.0406 - val_loss: 237.8179 - val_mean_squared_error: 237.8179\n",
      "Epoch 145/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 235.3283 - mean_squared_error: 235.3283 - val_loss: 234.7349 - val_mean_squared_error: 234.7349\n",
      "Epoch 146/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 232.0197 - mean_squared_error: 232.0197 - val_loss: 230.9947 - val_mean_squared_error: 230.9947\n",
      "Epoch 147/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 227.9215 - mean_squared_error: 227.9215 - val_loss: 226.3587 - val_mean_squared_error: 226.3587\n",
      "Epoch 148/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 223.2478 - mean_squared_error: 223.2478 - val_loss: 221.1835 - val_mean_squared_error: 221.1835\n",
      "Epoch 149/150\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 217.8172 - mean_squared_error: 217.8173 - val_loss: 215.2347 - val_mean_squared_error: 215.2347\n",
      "Epoch 150/150\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 211.4566 - mean_squared_error: 211.4566 - val_loss: 207.5969 - val_mean_squared_error: 207.5969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a923271250>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=10, activation='softmax'))\n",
    "model.add(Dense(8,activation='sigmoid'))\n",
    "model.add(Dense(1,activation=None))\n",
    "model.compile(loss='mean_squared_error', optimizer='adamax', metrics=['mean_squared_error'])\n",
    "model.fit(x_train,y_train, validation_split=0.3, epochs=150, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d2c566",
   "metadata": {},
   "source": [
    "# Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db511ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "148/148 [==============================] - 2s 8ms/step - loss: 18049.4199 - mean_squared_error: 18049.4199 - val_loss: 17803.6719 - val_mean_squared_error: 17803.6719\n",
      "Epoch 2/500\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 17741.5742 - mean_squared_error: 17741.5742 - val_loss: 17484.0938 - val_mean_squared_error: 17484.0938\n",
      "Epoch 3/500\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 17404.8945 - mean_squared_error: 17404.8945 - val_loss: 17137.1582 - val_mean_squared_error: 17137.1602\n",
      "Epoch 4/500\n",
      "148/148 [==============================] - 1s 8ms/step - loss: 17059.1602 - mean_squared_error: 17059.1602 - val_loss: 16802.4023 - val_mean_squared_error: 16802.4043\n",
      "Epoch 5/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 16750.4805 - mean_squared_error: 16750.4805 - val_loss: 16520.6836 - val_mean_squared_error: 16520.6836\n",
      "Epoch 6/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 16488.9062 - mean_squared_error: 16488.9062 - val_loss: 16274.1611 - val_mean_squared_error: 16274.1611\n",
      "Epoch 7/500\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 16249.5078 - mean_squared_error: 16249.5078 - val_loss: 16038.0605 - val_mean_squared_error: 16038.0605\n",
      "Epoch 8/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 16009.0605 - mean_squared_error: 16009.0605 - val_loss: 15790.6543 - val_mean_squared_error: 15790.6543\n",
      "Epoch 9/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 15747.7568 - mean_squared_error: 15747.7568 - val_loss: 15514.1826 - val_mean_squared_error: 15514.1826\n",
      "Epoch 10/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 15456.0186 - mean_squared_error: 15456.0186 - val_loss: 15211.8965 - val_mean_squared_error: 15211.8965\n",
      "Epoch 11/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 15147.3086 - mean_squared_error: 15147.3086 - val_loss: 14901.0293 - val_mean_squared_error: 14901.0293\n",
      "Epoch 12/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 14840.8145 - mean_squared_error: 14840.8145 - val_loss: 14603.0449 - val_mean_squared_error: 14603.0449\n",
      "Epoch 13/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 14549.5537 - mean_squared_error: 14549.5537 - val_loss: 14318.9160 - val_mean_squared_error: 14318.9160\n",
      "Epoch 14/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 14268.2334 - mean_squared_error: 14268.2334 - val_loss: 14042.2930 - val_mean_squared_error: 14042.2930\n",
      "Epoch 15/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 13994.3174 - mean_squared_error: 13994.3174 - val_loss: 13771.4668 - val_mean_squared_error: 13771.4668\n",
      "Epoch 16/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 13723.2607 - mean_squared_error: 13723.2607 - val_loss: 13502.7070 - val_mean_squared_error: 13502.7070\n",
      "Epoch 17/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 13455.6221 - mean_squared_error: 13455.6221 - val_loss: 13237.8389 - val_mean_squared_error: 13237.8389\n",
      "Epoch 18/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 13192.1475 - mean_squared_error: 13192.1475 - val_loss: 12976.5479 - val_mean_squared_error: 12976.5479\n",
      "Epoch 19/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 12932.3701 - mean_squared_error: 12932.3701 - val_loss: 12719.9814 - val_mean_squared_error: 12719.9814\n",
      "Epoch 20/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 12675.7529 - mean_squared_error: 12675.7529 - val_loss: 12465.3633 - val_mean_squared_error: 12465.3633\n",
      "Epoch 21/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 12420.6934 - mean_squared_error: 12420.6934 - val_loss: 12211.9883 - val_mean_squared_error: 12211.9883\n",
      "Epoch 22/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 12167.7598 - mean_squared_error: 12167.7598 - val_loss: 11961.2178 - val_mean_squared_error: 11961.2178\n",
      "Epoch 23/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 11918.0557 - mean_squared_error: 11918.0557 - val_loss: 11713.8428 - val_mean_squared_error: 11713.8428\n",
      "Epoch 24/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 11670.9111 - mean_squared_error: 11670.9111 - val_loss: 11469.1221 - val_mean_squared_error: 11469.1221\n",
      "Epoch 25/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 11427.3574 - mean_squared_error: 11427.3574 - val_loss: 11228.2227 - val_mean_squared_error: 11228.2227\n",
      "Epoch 26/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 11186.3613 - mean_squared_error: 11186.3613 - val_loss: 10988.9648 - val_mean_squared_error: 10988.9648\n",
      "Epoch 27/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 10947.7158 - mean_squared_error: 10947.7158 - val_loss: 10752.2080 - val_mean_squared_error: 10752.2080\n",
      "Epoch 28/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 10710.9678 - mean_squared_error: 10710.9678 - val_loss: 10517.8574 - val_mean_squared_error: 10517.8574\n",
      "Epoch 29/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 10477.1260 - mean_squared_error: 10477.1260 - val_loss: 10287.1006 - val_mean_squared_error: 10287.1006\n",
      "Epoch 30/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 10247.2061 - mean_squared_error: 10247.2061 - val_loss: 10058.7490 - val_mean_squared_error: 10058.7490\n",
      "Epoch 31/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 10019.9131 - mean_squared_error: 10019.9131 - val_loss: 9833.9023 - val_mean_squared_error: 9833.9023\n",
      "Epoch 32/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 9794.8291 - mean_squared_error: 9794.8291 - val_loss: 9611.5156 - val_mean_squared_error: 9611.5156\n",
      "Epoch 33/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 9572.6533 - mean_squared_error: 9572.6533 - val_loss: 9390.9570 - val_mean_squared_error: 9390.9570\n",
      "Epoch 34/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 9353.1719 - mean_squared_error: 9353.1719 - val_loss: 9173.4766 - val_mean_squared_error: 9173.4766\n",
      "Epoch 35/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 9136.0020 - mean_squared_error: 9136.0020 - val_loss: 8958.5371 - val_mean_squared_error: 8958.5371\n",
      "Epoch 36/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 8921.9814 - mean_squared_error: 8921.9814 - val_loss: 8746.6201 - val_mean_squared_error: 8746.6201\n",
      "Epoch 37/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 8710.5879 - mean_squared_error: 8710.5879 - val_loss: 8538.4688 - val_mean_squared_error: 8538.4688\n",
      "Epoch 38/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 8503.5791 - mean_squared_error: 8503.5791 - val_loss: 8332.8672 - val_mean_squared_error: 8332.8672\n",
      "Epoch 39/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 8297.7646 - mean_squared_error: 8297.7646 - val_loss: 8128.6089 - val_mean_squared_error: 8128.6079\n",
      "Epoch 40/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 8093.1304 - mean_squared_error: 8093.1304 - val_loss: 7926.4927 - val_mean_squared_error: 7926.4927\n",
      "Epoch 41/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 7892.6187 - mean_squared_error: 7892.6187 - val_loss: 7728.7070 - val_mean_squared_error: 7728.7070\n",
      "Epoch 42/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 7694.8262 - mean_squared_error: 7694.8262 - val_loss: 7533.3296 - val_mean_squared_error: 7533.3296\n",
      "Epoch 43/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 7499.7700 - mean_squared_error: 7499.7700 - val_loss: 7340.2280 - val_mean_squared_error: 7340.2280\n",
      "Epoch 44/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 7309.2329 - mean_squared_error: 7309.2329 - val_loss: 7152.5566 - val_mean_squared_error: 7152.5566\n",
      "Epoch 45/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 7119.8823 - mean_squared_error: 7119.8823 - val_loss: 6964.9990 - val_mean_squared_error: 6964.9990\n",
      "Epoch 46/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 6933.0264 - mean_squared_error: 6933.0264 - val_loss: 6780.7305 - val_mean_squared_error: 6780.7305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 6749.5854 - mean_squared_error: 6749.5854 - val_loss: 6598.8530 - val_mean_squared_error: 6598.8530\n",
      "Epoch 48/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 6567.7021 - mean_squared_error: 6567.7021 - val_loss: 6419.4624 - val_mean_squared_error: 6419.4624\n",
      "Epoch 49/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 6388.4844 - mean_squared_error: 6388.4844 - val_loss: 6241.6294 - val_mean_squared_error: 6241.6294\n",
      "Epoch 50/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 6211.4121 - mean_squared_error: 6211.4121 - val_loss: 6068.6323 - val_mean_squared_error: 6068.6323\n",
      "Epoch 51/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 6039.1572 - mean_squared_error: 6039.1572 - val_loss: 5898.5000 - val_mean_squared_error: 5898.5000\n",
      "Epoch 52/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 5869.7808 - mean_squared_error: 5869.7808 - val_loss: 5730.0840 - val_mean_squared_error: 5730.0840\n",
      "Epoch 53/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 5701.8096 - mean_squared_error: 5701.8096 - val_loss: 5564.6787 - val_mean_squared_error: 5564.6787\n",
      "Epoch 54/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 5536.4580 - mean_squared_error: 5536.4580 - val_loss: 5400.5811 - val_mean_squared_error: 5400.5806\n",
      "Epoch 55/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 5373.6118 - mean_squared_error: 5373.6118 - val_loss: 5241.9463 - val_mean_squared_error: 5241.9463\n",
      "Epoch 56/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 5215.8335 - mean_squared_error: 5215.8335 - val_loss: 5085.0850 - val_mean_squared_error: 5085.0850\n",
      "Epoch 57/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 5058.6519 - mean_squared_error: 5058.6523 - val_loss: 4931.1416 - val_mean_squared_error: 4931.1416\n",
      "Epoch 58/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 4905.6797 - mean_squared_error: 4905.6797 - val_loss: 4780.3408 - val_mean_squared_error: 4780.3408\n",
      "Epoch 59/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4755.1499 - mean_squared_error: 4755.1499 - val_loss: 4631.3481 - val_mean_squared_error: 4631.3481\n",
      "Epoch 60/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4605.6343 - mean_squared_error: 4605.6343 - val_loss: 4483.5054 - val_mean_squared_error: 4483.5054\n",
      "Epoch 61/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 4459.3667 - mean_squared_error: 4459.3667 - val_loss: 4340.7104 - val_mean_squared_error: 4340.7104\n",
      "Epoch 62/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 4316.4385 - mean_squared_error: 4316.4385 - val_loss: 4199.3770 - val_mean_squared_error: 4199.3774\n",
      "Epoch 63/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 4177.0420 - mean_squared_error: 4177.0420 - val_loss: 4062.9539 - val_mean_squared_error: 4062.9539\n",
      "Epoch 64/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 4039.2554 - mean_squared_error: 4039.2554 - val_loss: 3925.7671 - val_mean_squared_error: 3925.7671\n",
      "Epoch 65/500\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 3903.6282 - mean_squared_error: 3903.6282 - val_loss: 3792.7766 - val_mean_squared_error: 3792.7766\n",
      "Epoch 66/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 3770.0649 - mean_squared_error: 3770.0649 - val_loss: 3660.7759 - val_mean_squared_error: 3660.7759\n",
      "Epoch 67/500\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 3639.1426 - mean_squared_error: 3639.1426 - val_loss: 3532.9778 - val_mean_squared_error: 3532.9778\n",
      "Epoch 68/500\n",
      "148/148 [==============================] - 1s 9ms/step - loss: 3511.4641 - mean_squared_error: 3511.4641 - val_loss: 3407.0457 - val_mean_squared_error: 3407.0457\n",
      "Epoch 69/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 3386.1987 - mean_squared_error: 3386.1987 - val_loss: 3283.4504 - val_mean_squared_error: 3283.4504\n",
      "Epoch 70/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 3263.9907 - mean_squared_error: 3263.9907 - val_loss: 3164.4890 - val_mean_squared_error: 3164.4890\n",
      "Epoch 71/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 3144.0137 - mean_squared_error: 3144.0137 - val_loss: 3045.4985 - val_mean_squared_error: 3045.4985\n",
      "Epoch 72/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 3027.1851 - mean_squared_error: 3027.1851 - val_loss: 2931.8835 - val_mean_squared_error: 2931.8835\n",
      "Epoch 73/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 2912.3582 - mean_squared_error: 2912.3582 - val_loss: 2819.9385 - val_mean_squared_error: 2819.9385\n",
      "Epoch 74/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 2802.6992 - mean_squared_error: 2802.6992 - val_loss: 2710.6724 - val_mean_squared_error: 2710.6724\n",
      "Epoch 75/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 2692.5649 - mean_squared_error: 2692.5649 - val_loss: 2603.0051 - val_mean_squared_error: 2603.0051\n",
      "Epoch 76/500\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 2585.4031 - mean_squared_error: 2585.4031 - val_loss: 2498.1860 - val_mean_squared_error: 2498.1860\n",
      "Epoch 77/500\n",
      "148/148 [==============================] - 1s 8ms/step - loss: 2481.4819 - mean_squared_error: 2481.4819 - val_loss: 2396.7034 - val_mean_squared_error: 2396.7031\n",
      "Epoch 78/500\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 2380.6726 - mean_squared_error: 2380.6726 - val_loss: 2298.0339 - val_mean_squared_error: 2298.0337\n",
      "Epoch 79/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 2282.9644 - mean_squared_error: 2282.9644 - val_loss: 2201.4966 - val_mean_squared_error: 2201.4966\n",
      "Epoch 80/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 2185.3408 - mean_squared_error: 2185.3408 - val_loss: 2106.1123 - val_mean_squared_error: 2106.1123\n",
      "Epoch 81/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 2089.6648 - mean_squared_error: 2089.6648 - val_loss: 2012.2888 - val_mean_squared_error: 2012.2887\n",
      "Epoch 82/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1996.7535 - mean_squared_error: 1996.7535 - val_loss: 1920.8025 - val_mean_squared_error: 1920.8025\n",
      "Epoch 83/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1902.4167 - mean_squared_error: 1902.4167 - val_loss: 1825.2908 - val_mean_squared_error: 1825.2908\n",
      "Epoch 84/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1806.4661 - mean_squared_error: 1806.4661 - val_loss: 1731.6896 - val_mean_squared_error: 1731.6896\n",
      "Epoch 85/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1712.2983 - mean_squared_error: 1712.2983 - val_loss: 1638.4338 - val_mean_squared_error: 1638.4338\n",
      "Epoch 86/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1616.8688 - mean_squared_error: 1616.8688 - val_loss: 1542.5775 - val_mean_squared_error: 1542.5775\n",
      "Epoch 87/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1519.1932 - mean_squared_error: 1519.1932 - val_loss: 1446.2274 - val_mean_squared_error: 1446.2274\n",
      "Epoch 88/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1426.2787 - mean_squared_error: 1426.2787 - val_loss: 1359.5676 - val_mean_squared_error: 1359.5676\n",
      "Epoch 89/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1342.8291 - mean_squared_error: 1342.8291 - val_loss: 1279.9749 - val_mean_squared_error: 1279.9749\n",
      "Epoch 90/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1264.5269 - mean_squared_error: 1264.5269 - val_loss: 1204.3010 - val_mean_squared_error: 1204.3011\n",
      "Epoch 91/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1190.7174 - mean_squared_error: 1190.7174 - val_loss: 1133.1432 - val_mean_squared_error: 1133.1432\n",
      "Epoch 92/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1120.8105 - mean_squared_error: 1120.8105 - val_loss: 1067.4913 - val_mean_squared_error: 1067.4913\n",
      "Epoch 93/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 1s 5ms/step - loss: 1054.7379 - mean_squared_error: 1054.7379 - val_loss: 1001.8439 - val_mean_squared_error: 1001.8439\n",
      "Epoch 94/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 990.1624 - mean_squared_error: 990.1624 - val_loss: 941.0667 - val_mean_squared_error: 941.0667\n",
      "Epoch 95/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 930.5026 - mean_squared_error: 930.5026 - val_loss: 883.3058 - val_mean_squared_error: 883.3058\n",
      "Epoch 96/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 872.1588 - mean_squared_error: 872.1588 - val_loss: 826.9405 - val_mean_squared_error: 826.9405\n",
      "Epoch 97/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 817.0601 - mean_squared_error: 817.0601 - val_loss: 774.7287 - val_mean_squared_error: 774.7287\n",
      "Epoch 98/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 765.8332 - mean_squared_error: 765.8332 - val_loss: 726.1881 - val_mean_squared_error: 726.1881\n",
      "Epoch 99/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 718.7683 - mean_squared_error: 718.7683 - val_loss: 681.1321 - val_mean_squared_error: 681.1321\n",
      "Epoch 100/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 673.1449 - mean_squared_error: 673.1449 - val_loss: 638.0400 - val_mean_squared_error: 638.0400\n",
      "Epoch 101/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 631.1582 - mean_squared_error: 631.1583 - val_loss: 597.4430 - val_mean_squared_error: 597.4430\n",
      "Epoch 102/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 589.9047 - mean_squared_error: 589.9047 - val_loss: 557.7467 - val_mean_squared_error: 557.7467\n",
      "Epoch 103/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 550.9225 - mean_squared_error: 550.9225 - val_loss: 521.8859 - val_mean_squared_error: 521.8859\n",
      "Epoch 104/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 516.0939 - mean_squared_error: 516.0939 - val_loss: 489.4420 - val_mean_squared_error: 489.4420\n",
      "Epoch 105/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 484.3976 - mean_squared_error: 484.3976 - val_loss: 459.3795 - val_mean_squared_error: 459.3795\n",
      "Epoch 106/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 454.5055 - mean_squared_error: 454.5055 - val_loss: 431.8657 - val_mean_squared_error: 431.8657\n",
      "Epoch 107/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 428.5752 - mean_squared_error: 428.5752 - val_loss: 408.2050 - val_mean_squared_error: 408.2050\n",
      "Epoch 108/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 404.5006 - mean_squared_error: 404.5006 - val_loss: 384.8818 - val_mean_squared_error: 384.8818\n",
      "Epoch 109/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 381.0476 - mean_squared_error: 381.0476 - val_loss: 363.4694 - val_mean_squared_error: 363.4694\n",
      "Epoch 110/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 360.0023 - mean_squared_error: 360.0023 - val_loss: 343.4974 - val_mean_squared_error: 343.4974\n",
      "Epoch 111/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 338.4742 - mean_squared_error: 338.4742 - val_loss: 322.0233 - val_mean_squared_error: 322.0233\n",
      "Epoch 112/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 315.8188 - mean_squared_error: 315.8188 - val_loss: 301.1454 - val_mean_squared_error: 301.1454\n",
      "Epoch 113/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 295.8159 - mean_squared_error: 295.8159 - val_loss: 282.2858 - val_mean_squared_error: 282.2858\n",
      "Epoch 114/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 278.5146 - mean_squared_error: 278.5146 - val_loss: 266.6559 - val_mean_squared_error: 266.6559\n",
      "Epoch 115/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 263.9078 - mean_squared_error: 263.9078 - val_loss: 253.4048 - val_mean_squared_error: 253.4048\n",
      "Epoch 116/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 251.6050 - mean_squared_error: 251.6050 - val_loss: 242.4877 - val_mean_squared_error: 242.4877\n",
      "Epoch 117/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 242.1003 - mean_squared_error: 242.1003 - val_loss: 234.8670 - val_mean_squared_error: 234.8670\n",
      "Epoch 118/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 234.4079 - mean_squared_error: 234.4079 - val_loss: 227.6761 - val_mean_squared_error: 227.6761\n",
      "Epoch 119/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 227.1584 - mean_squared_error: 227.1584 - val_loss: 221.0119 - val_mean_squared_error: 221.0119\n",
      "Epoch 120/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 220.6511 - mean_squared_error: 220.6511 - val_loss: 215.4292 - val_mean_squared_error: 215.4292\n",
      "Epoch 121/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 215.2026 - mean_squared_error: 215.2026 - val_loss: 210.6904 - val_mean_squared_error: 210.6904\n",
      "Epoch 122/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 210.5253 - mean_squared_error: 210.5253 - val_loss: 206.7599 - val_mean_squared_error: 206.7599\n",
      "Epoch 123/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 206.6529 - mean_squared_error: 206.6529 - val_loss: 203.5156 - val_mean_squared_error: 203.5156\n",
      "Epoch 124/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 203.5580 - mean_squared_error: 203.5580 - val_loss: 201.1713 - val_mean_squared_error: 201.1713\n",
      "Epoch 125/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 201.2906 - mean_squared_error: 201.2906 - val_loss: 199.3913 - val_mean_squared_error: 199.3913\n",
      "Epoch 126/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 199.4853 - mean_squared_error: 199.4853 - val_loss: 197.8435 - val_mean_squared_error: 197.8435\n",
      "Epoch 127/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 197.8726 - mean_squared_error: 197.8726 - val_loss: 196.5116 - val_mean_squared_error: 196.5116\n",
      "Epoch 128/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 196.4270 - mean_squared_error: 196.4270 - val_loss: 195.3681 - val_mean_squared_error: 195.3681\n",
      "Epoch 129/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 195.0663 - mean_squared_error: 195.0663 - val_loss: 194.1563 - val_mean_squared_error: 194.1563\n",
      "Epoch 130/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 193.7610 - mean_squared_error: 193.7610 - val_loss: 193.1788 - val_mean_squared_error: 193.1788\n",
      "Epoch 131/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 192.5084 - mean_squared_error: 192.5084 - val_loss: 192.1090 - val_mean_squared_error: 192.1090\n",
      "Epoch 132/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 191.1472 - mean_squared_error: 191.1472 - val_loss: 191.0366 - val_mean_squared_error: 191.0366\n",
      "Epoch 133/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 189.6669 - mean_squared_error: 189.6669 - val_loss: 189.8970 - val_mean_squared_error: 189.8970\n",
      "Epoch 134/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 187.6908 - mean_squared_error: 187.6908 - val_loss: 188.0496 - val_mean_squared_error: 188.0496\n",
      "Epoch 135/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 184.7497 - mean_squared_error: 184.7497 - val_loss: 184.4506 - val_mean_squared_error: 184.4506\n",
      "Epoch 136/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 180.9218 - mean_squared_error: 180.9218 - val_loss: 179.4902 - val_mean_squared_error: 179.4902\n",
      "Epoch 137/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 174.0071 - mean_squared_error: 174.0071 - val_loss: 167.8558 - val_mean_squared_error: 167.8558\n",
      "Epoch 138/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 156.3174 - mean_squared_error: 156.3174 - val_loss: 139.9998 - val_mean_squared_error: 139.9998\n",
      "Epoch 139/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 131.1246 - mean_squared_error: 131.1246 - val_loss: 118.1274 - val_mean_squared_error: 118.1274\n",
      "Epoch 140/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 1s 6ms/step - loss: 112.6951 - mean_squared_error: 112.6951 - val_loss: 102.2084 - val_mean_squared_error: 102.2084\n",
      "Epoch 141/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 98.8202 - mean_squared_error: 98.8202 - val_loss: 90.0657 - val_mean_squared_error: 90.0657\n",
      "Epoch 142/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 88.4297 - mean_squared_error: 88.4297 - val_loss: 80.8678 - val_mean_squared_error: 80.8678\n",
      "Epoch 143/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 80.3197 - mean_squared_error: 80.3197 - val_loss: 73.6597 - val_mean_squared_error: 73.6597\n",
      "Epoch 144/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 73.7250 - mean_squared_error: 73.7250 - val_loss: 67.8291 - val_mean_squared_error: 67.8291\n",
      "Epoch 145/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 68.3869 - mean_squared_error: 68.3869 - val_loss: 63.2424 - val_mean_squared_error: 63.2424\n",
      "Epoch 146/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 64.0109 - mean_squared_error: 64.0109 - val_loss: 59.3350 - val_mean_squared_error: 59.3350\n",
      "Epoch 147/500\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 60.2822 - mean_squared_error: 60.2822 - val_loss: 56.1226 - val_mean_squared_error: 56.1226\n",
      "Epoch 148/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 57.3853 - mean_squared_error: 57.3853 - val_loss: 53.7482 - val_mean_squared_error: 53.7482\n",
      "Epoch 149/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 55.0420 - mean_squared_error: 55.0420 - val_loss: 51.7231 - val_mean_squared_error: 51.7231\n",
      "Epoch 150/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 53.0367 - mean_squared_error: 53.0367 - val_loss: 49.9860 - val_mean_squared_error: 49.9860\n",
      "Epoch 151/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 51.3960 - mean_squared_error: 51.3960 - val_loss: 48.5719 - val_mean_squared_error: 48.5719\n",
      "Epoch 152/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 50.0009 - mean_squared_error: 50.0009 - val_loss: 47.3533 - val_mean_squared_error: 47.3533\n",
      "Epoch 153/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 48.8644 - mean_squared_error: 48.8644 - val_loss: 46.3585 - val_mean_squared_error: 46.3585\n",
      "Epoch 154/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 47.8840 - mean_squared_error: 47.8840 - val_loss: 45.4573 - val_mean_squared_error: 45.4573\n",
      "Epoch 155/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 46.9900 - mean_squared_error: 46.9900 - val_loss: 44.6248 - val_mean_squared_error: 44.6248\n",
      "Epoch 156/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 46.1708 - mean_squared_error: 46.1708 - val_loss: 43.8243 - val_mean_squared_error: 43.8243\n",
      "Epoch 157/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 45.3905 - mean_squared_error: 45.3905 - val_loss: 43.0534 - val_mean_squared_error: 43.0534\n",
      "Epoch 158/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 44.6504 - mean_squared_error: 44.6504 - val_loss: 42.3366 - val_mean_squared_error: 42.3366\n",
      "Epoch 159/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 43.9614 - mean_squared_error: 43.9614 - val_loss: 41.6619 - val_mean_squared_error: 41.6619\n",
      "Epoch 160/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 43.2763 - mean_squared_error: 43.2763 - val_loss: 41.0141 - val_mean_squared_error: 41.0141\n",
      "Epoch 161/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 42.6084 - mean_squared_error: 42.6084 - val_loss: 40.3534 - val_mean_squared_error: 40.3534\n",
      "Epoch 162/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 41.8758 - mean_squared_error: 41.8758 - val_loss: 39.5984 - val_mean_squared_error: 39.5984\n",
      "Epoch 163/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 41.0343 - mean_squared_error: 41.0343 - val_loss: 38.7333 - val_mean_squared_error: 38.7333\n",
      "Epoch 164/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 40.1313 - mean_squared_error: 40.1313 - val_loss: 37.8358 - val_mean_squared_error: 37.8358\n",
      "Epoch 165/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 39.2022 - mean_squared_error: 39.2022 - val_loss: 36.8790 - val_mean_squared_error: 36.8790\n",
      "Epoch 166/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 38.1978 - mean_squared_error: 38.1978 - val_loss: 35.8577 - val_mean_squared_error: 35.8577\n",
      "Epoch 167/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 37.1009 - mean_squared_error: 37.1009 - val_loss: 34.7300 - val_mean_squared_error: 34.7300\n",
      "Epoch 168/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 35.8554 - mean_squared_error: 35.8554 - val_loss: 33.4708 - val_mean_squared_error: 33.4708\n",
      "Epoch 169/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 34.4248 - mean_squared_error: 34.4248 - val_loss: 32.0036 - val_mean_squared_error: 32.0036\n",
      "Epoch 170/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 32.5126 - mean_squared_error: 32.5126 - val_loss: 29.8296 - val_mean_squared_error: 29.8296\n",
      "Epoch 171/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 29.6724 - mean_squared_error: 29.6724 - val_loss: 26.5926 - val_mean_squared_error: 26.5926\n",
      "Epoch 172/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 26.0870 - mean_squared_error: 26.0870 - val_loss: 23.2071 - val_mean_squared_error: 23.2071\n",
      "Epoch 173/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 23.2641 - mean_squared_error: 23.2641 - val_loss: 20.9077 - val_mean_squared_error: 20.9077\n",
      "Epoch 174/500\n",
      "148/148 [==============================] - 1s 9ms/step - loss: 20.9452 - mean_squared_error: 20.9452 - val_loss: 18.7601 - val_mean_squared_error: 18.7601\n",
      "Epoch 175/500\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 18.7907 - mean_squared_error: 18.7907 - val_loss: 16.8605 - val_mean_squared_error: 16.8605\n",
      "Epoch 176/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 17.0600 - mean_squared_error: 17.0600 - val_loss: 15.3760 - val_mean_squared_error: 15.3760\n",
      "Epoch 177/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 15.5630 - mean_squared_error: 15.5630 - val_loss: 13.9678 - val_mean_squared_error: 13.9678\n",
      "Epoch 178/500\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 14.1244 - mean_squared_error: 14.1244 - val_loss: 12.6213 - val_mean_squared_error: 12.6213\n",
      "Epoch 179/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 12.7425 - mean_squared_error: 12.7425 - val_loss: 11.3556 - val_mean_squared_error: 11.3556\n",
      "Epoch 180/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 11.4860 - mean_squared_error: 11.4860 - val_loss: 10.2624 - val_mean_squared_error: 10.2624\n",
      "Epoch 181/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 10.3606 - mean_squared_error: 10.3606 - val_loss: 9.2843 - val_mean_squared_error: 9.2843\n",
      "Epoch 182/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 9.4465 - mean_squared_error: 9.4465 - val_loss: 8.5412 - val_mean_squared_error: 8.5412\n",
      "Epoch 183/500\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 8.6832 - mean_squared_error: 8.6832 - val_loss: 7.8576 - val_mean_squared_error: 7.8576\n",
      "Epoch 184/500\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 7.9825 - mean_squared_error: 7.9825 - val_loss: 7.2693 - val_mean_squared_error: 7.2693\n",
      "Epoch 185/500\n",
      "148/148 [==============================] - 1s 9ms/step - loss: 7.3947 - mean_squared_error: 7.3947 - val_loss: 6.7618 - val_mean_squared_error: 6.7618\n",
      "Epoch 186/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 6.8652 - mean_squared_error: 6.8652 - val_loss: 6.2961 - val_mean_squared_error: 6.2961\n",
      "Epoch 187/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 6.3932 - mean_squared_error: 6.3932 - val_loss: 5.8962 - val_mean_squared_error: 5.8962\n",
      "Epoch 188/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 5.9779 - mean_squared_error: 5.9779 - val_loss: 5.5572 - val_mean_squared_error: 5.5572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 189/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 5.6227 - mean_squared_error: 5.6227 - val_loss: 5.2733 - val_mean_squared_error: 5.2733\n",
      "Epoch 190/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 5.3430 - mean_squared_error: 5.3430 - val_loss: 5.0612 - val_mean_squared_error: 5.0612\n",
      "Epoch 191/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 5.1104 - mean_squared_error: 5.1104 - val_loss: 4.8707 - val_mean_squared_error: 4.8707\n",
      "Epoch 192/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 4.9022 - mean_squared_error: 4.9022 - val_loss: 4.6944 - val_mean_squared_error: 4.6944\n",
      "Epoch 193/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 4.7094 - mean_squared_error: 4.7094 - val_loss: 4.5323 - val_mean_squared_error: 4.5323\n",
      "Epoch 194/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 4.5413 - mean_squared_error: 4.5413 - val_loss: 4.3985 - val_mean_squared_error: 4.3985\n",
      "Epoch 195/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 4.3989 - mean_squared_error: 4.3989 - val_loss: 4.2745 - val_mean_squared_error: 4.2745\n",
      "Epoch 196/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 4.2752 - mean_squared_error: 4.2752 - val_loss: 4.1709 - val_mean_squared_error: 4.1709\n",
      "Epoch 197/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 4.1558 - mean_squared_error: 4.1558 - val_loss: 4.0701 - val_mean_squared_error: 4.0701\n",
      "Epoch 198/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 4.0468 - mean_squared_error: 4.0468 - val_loss: 3.9697 - val_mean_squared_error: 3.9697\n",
      "Epoch 199/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 3.9551 - mean_squared_error: 3.9551 - val_loss: 3.8785 - val_mean_squared_error: 3.8785\n",
      "Epoch 200/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 3.8649 - mean_squared_error: 3.8649 - val_loss: 3.7837 - val_mean_squared_error: 3.7837\n",
      "Epoch 201/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 3.7766 - mean_squared_error: 3.7766 - val_loss: 3.6995 - val_mean_squared_error: 3.6995\n",
      "Epoch 202/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 3.6961 - mean_squared_error: 3.6961 - val_loss: 3.6163 - val_mean_squared_error: 3.6163\n",
      "Epoch 203/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 3.6200 - mean_squared_error: 3.6200 - val_loss: 3.5459 - val_mean_squared_error: 3.5459\n",
      "Epoch 204/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 3.5506 - mean_squared_error: 3.5506 - val_loss: 3.4802 - val_mean_squared_error: 3.4802\n",
      "Epoch 205/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 3.4769 - mean_squared_error: 3.4769 - val_loss: 3.3991 - val_mean_squared_error: 3.3991\n",
      "Epoch 206/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 3.4029 - mean_squared_error: 3.4029 - val_loss: 3.3309 - val_mean_squared_error: 3.3309\n",
      "Epoch 207/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 3.3333 - mean_squared_error: 3.3333 - val_loss: 3.2593 - val_mean_squared_error: 3.2593\n",
      "Epoch 208/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 3.2640 - mean_squared_error: 3.2640 - val_loss: 3.1901 - val_mean_squared_error: 3.1901\n",
      "Epoch 209/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 3.1958 - mean_squared_error: 3.1958 - val_loss: 3.1309 - val_mean_squared_error: 3.1309\n",
      "Epoch 210/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 3.1321 - mean_squared_error: 3.1321 - val_loss: 3.0729 - val_mean_squared_error: 3.0729\n",
      "Epoch 211/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 3.0718 - mean_squared_error: 3.0718 - val_loss: 3.0259 - val_mean_squared_error: 3.0259\n",
      "Epoch 212/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 3.0162 - mean_squared_error: 3.0162 - val_loss: 2.9741 - val_mean_squared_error: 2.9741\n",
      "Epoch 213/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 2.9611 - mean_squared_error: 2.9611 - val_loss: 2.9257 - val_mean_squared_error: 2.9257\n",
      "Epoch 214/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 2.9048 - mean_squared_error: 2.9048 - val_loss: 2.8773 - val_mean_squared_error: 2.8773\n",
      "Epoch 215/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 2.8510 - mean_squared_error: 2.8510 - val_loss: 2.8290 - val_mean_squared_error: 2.8290\n",
      "Epoch 216/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 2.7988 - mean_squared_error: 2.7988 - val_loss: 2.7841 - val_mean_squared_error: 2.7841\n",
      "Epoch 217/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 2.7463 - mean_squared_error: 2.7463 - val_loss: 2.7365 - val_mean_squared_error: 2.7365\n",
      "Epoch 218/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 2.6934 - mean_squared_error: 2.6934 - val_loss: 2.6864 - val_mean_squared_error: 2.6864\n",
      "Epoch 219/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 2.6441 - mean_squared_error: 2.6441 - val_loss: 2.6454 - val_mean_squared_error: 2.6454\n",
      "Epoch 220/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 2.5952 - mean_squared_error: 2.5952 - val_loss: 2.5972 - val_mean_squared_error: 2.5972\n",
      "Epoch 221/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 2.5515 - mean_squared_error: 2.5515 - val_loss: 2.5610 - val_mean_squared_error: 2.5610\n",
      "Epoch 222/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 2.5057 - mean_squared_error: 2.5057 - val_loss: 2.5154 - val_mean_squared_error: 2.5154\n",
      "Epoch 223/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 2.4628 - mean_squared_error: 2.4628 - val_loss: 2.4759 - val_mean_squared_error: 2.4759\n",
      "Epoch 224/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 2.4224 - mean_squared_error: 2.4224 - val_loss: 2.4223 - val_mean_squared_error: 2.4223\n",
      "Epoch 225/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 2.3786 - mean_squared_error: 2.3786 - val_loss: 2.3757 - val_mean_squared_error: 2.3757\n",
      "Epoch 226/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 2.3357 - mean_squared_error: 2.3357 - val_loss: 2.3310 - val_mean_squared_error: 2.3310\n",
      "Epoch 227/500\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 2.2995 - mean_squared_error: 2.2995 - val_loss: 2.2835 - val_mean_squared_error: 2.2835\n",
      "Epoch 228/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 2.2587 - mean_squared_error: 2.2587 - val_loss: 2.2460 - val_mean_squared_error: 2.2460\n",
      "Epoch 229/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 2.2223 - mean_squared_error: 2.2223 - val_loss: 2.1896 - val_mean_squared_error: 2.1896\n",
      "Epoch 230/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 2.1785 - mean_squared_error: 2.1785 - val_loss: 2.1485 - val_mean_squared_error: 2.1485\n",
      "Epoch 231/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 2.1400 - mean_squared_error: 2.1400 - val_loss: 2.0891 - val_mean_squared_error: 2.0891\n",
      "Epoch 232/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 2.0986 - mean_squared_error: 2.0986 - val_loss: 2.0396 - val_mean_squared_error: 2.0396\n",
      "Epoch 233/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 2.0574 - mean_squared_error: 2.0574 - val_loss: 1.9873 - val_mean_squared_error: 1.9873\n",
      "Epoch 234/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 2.0151 - mean_squared_error: 2.0151 - val_loss: 1.9380 - val_mean_squared_error: 1.9380\n",
      "Epoch 235/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1.9680 - mean_squared_error: 1.9680 - val_loss: 1.8772 - val_mean_squared_error: 1.8772\n",
      "Epoch 236/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 1.9192 - mean_squared_error: 1.9192 - val_loss: 1.8230 - val_mean_squared_error: 1.8230\n",
      "Epoch 237/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1.8709 - mean_squared_error: 1.8709 - val_loss: 1.7713 - val_mean_squared_error: 1.7713\n",
      "Epoch 238/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 1s 5ms/step - loss: 1.8220 - mean_squared_error: 1.8220 - val_loss: 1.7169 - val_mean_squared_error: 1.7169\n",
      "Epoch 239/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 1.7751 - mean_squared_error: 1.7751 - val_loss: 1.6664 - val_mean_squared_error: 1.6664\n",
      "Epoch 240/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1.7354 - mean_squared_error: 1.7354 - val_loss: 1.6187 - val_mean_squared_error: 1.6187\n",
      "Epoch 241/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 1.6909 - mean_squared_error: 1.6909 - val_loss: 1.5759 - val_mean_squared_error: 1.5759\n",
      "Epoch 242/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 1.6525 - mean_squared_error: 1.6525 - val_loss: 1.5366 - val_mean_squared_error: 1.5366\n",
      "Epoch 243/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 1.6148 - mean_squared_error: 1.6148 - val_loss: 1.4969 - val_mean_squared_error: 1.4969\n",
      "Epoch 244/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1.5739 - mean_squared_error: 1.5739 - val_loss: 1.4564 - val_mean_squared_error: 1.4564\n",
      "Epoch 245/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 1.5346 - mean_squared_error: 1.5346 - val_loss: 1.4139 - val_mean_squared_error: 1.4139\n",
      "Epoch 246/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 1.4965 - mean_squared_error: 1.4965 - val_loss: 1.3775 - val_mean_squared_error: 1.3775\n",
      "Epoch 247/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1.4563 - mean_squared_error: 1.4563 - val_loss: 1.3432 - val_mean_squared_error: 1.3432\n",
      "Epoch 248/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 1.4180 - mean_squared_error: 1.4180 - val_loss: 1.3033 - val_mean_squared_error: 1.3033\n",
      "Epoch 249/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 1.3745 - mean_squared_error: 1.3745 - val_loss: 1.2611 - val_mean_squared_error: 1.2611\n",
      "Epoch 250/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 1.3281 - mean_squared_error: 1.3281 - val_loss: 1.2201 - val_mean_squared_error: 1.2201\n",
      "Epoch 251/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 1.2848 - mean_squared_error: 1.2848 - val_loss: 1.1914 - val_mean_squared_error: 1.1914\n",
      "Epoch 252/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 1.2450 - mean_squared_error: 1.2450 - val_loss: 1.1573 - val_mean_squared_error: 1.1573\n",
      "Epoch 253/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 1.2042 - mean_squared_error: 1.2042 - val_loss: 1.1159 - val_mean_squared_error: 1.1159\n",
      "Epoch 254/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1.1641 - mean_squared_error: 1.1641 - val_loss: 1.0875 - val_mean_squared_error: 1.0875\n",
      "Epoch 255/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 1.1273 - mean_squared_error: 1.1273 - val_loss: 1.0581 - val_mean_squared_error: 1.0581\n",
      "Epoch 256/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1.0897 - mean_squared_error: 1.0897 - val_loss: 1.0279 - val_mean_squared_error: 1.0279\n",
      "Epoch 257/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1.0558 - mean_squared_error: 1.0558 - val_loss: 1.0051 - val_mean_squared_error: 1.0051\n",
      "Epoch 258/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 1.0261 - mean_squared_error: 1.0261 - val_loss: 0.9772 - val_mean_squared_error: 0.9772\n",
      "Epoch 259/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.9944 - mean_squared_error: 0.9944 - val_loss: 0.9643 - val_mean_squared_error: 0.9643\n",
      "Epoch 260/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.9653 - mean_squared_error: 0.9653 - val_loss: 0.9302 - val_mean_squared_error: 0.9302\n",
      "Epoch 261/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.9384 - mean_squared_error: 0.9384 - val_loss: 0.9082 - val_mean_squared_error: 0.9082\n",
      "Epoch 262/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.9132 - mean_squared_error: 0.9132 - val_loss: 0.8889 - val_mean_squared_error: 0.8889\n",
      "Epoch 263/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.8852 - mean_squared_error: 0.8852 - val_loss: 0.8646 - val_mean_squared_error: 0.8646\n",
      "Epoch 264/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.8606 - mean_squared_error: 0.8606 - val_loss: 0.8504 - val_mean_squared_error: 0.8504\n",
      "Epoch 265/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.8394 - mean_squared_error: 0.8394 - val_loss: 0.8281 - val_mean_squared_error: 0.8281\n",
      "Epoch 266/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.8161 - mean_squared_error: 0.8161 - val_loss: 0.8093 - val_mean_squared_error: 0.8093\n",
      "Epoch 267/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.7965 - mean_squared_error: 0.7965 - val_loss: 0.7900 - val_mean_squared_error: 0.7900\n",
      "Epoch 268/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.7731 - mean_squared_error: 0.7731 - val_loss: 0.7711 - val_mean_squared_error: 0.7711\n",
      "Epoch 269/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.7530 - mean_squared_error: 0.7530 - val_loss: 0.7554 - val_mean_squared_error: 0.7554\n",
      "Epoch 270/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.7337 - mean_squared_error: 0.7337 - val_loss: 0.7435 - val_mean_squared_error: 0.7435\n",
      "Epoch 271/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.7186 - mean_squared_error: 0.7186 - val_loss: 0.7223 - val_mean_squared_error: 0.7223\n",
      "Epoch 272/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.7015 - mean_squared_error: 0.7015 - val_loss: 0.7100 - val_mean_squared_error: 0.7100\n",
      "Epoch 273/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6865 - mean_squared_error: 0.6865 - val_loss: 0.6985 - val_mean_squared_error: 0.6985\n",
      "Epoch 274/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.6731 - mean_squared_error: 0.6731 - val_loss: 0.6832 - val_mean_squared_error: 0.6832\n",
      "Epoch 275/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6573 - mean_squared_error: 0.6573 - val_loss: 0.6750 - val_mean_squared_error: 0.6750\n",
      "Epoch 276/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.6435 - mean_squared_error: 0.6435 - val_loss: 0.6606 - val_mean_squared_error: 0.6606\n",
      "Epoch 277/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6316 - mean_squared_error: 0.6316 - val_loss: 0.6494 - val_mean_squared_error: 0.6494\n",
      "Epoch 278/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.6210 - mean_squared_error: 0.6210 - val_loss: 0.6315 - val_mean_squared_error: 0.6315\n",
      "Epoch 279/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.6087 - mean_squared_error: 0.6087 - val_loss: 0.6207 - val_mean_squared_error: 0.6207\n",
      "Epoch 280/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5991 - mean_squared_error: 0.5991 - val_loss: 0.6134 - val_mean_squared_error: 0.6134\n",
      "Epoch 281/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5883 - mean_squared_error: 0.5883 - val_loss: 0.6046 - val_mean_squared_error: 0.6046\n",
      "Epoch 282/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5815 - mean_squared_error: 0.5815 - val_loss: 0.5987 - val_mean_squared_error: 0.5987\n",
      "Epoch 283/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5713 - mean_squared_error: 0.5713 - val_loss: 0.5833 - val_mean_squared_error: 0.5833\n",
      "Epoch 284/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5620 - mean_squared_error: 0.5620 - val_loss: 0.5737 - val_mean_squared_error: 0.5737\n",
      "Epoch 285/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5544 - mean_squared_error: 0.5544 - val_loss: 0.5716 - val_mean_squared_error: 0.5716\n",
      "Epoch 286/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5494 - mean_squared_error: 0.5494 - val_loss: 0.5611 - val_mean_squared_error: 0.5611\n",
      "Epoch 287/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5408 - mean_squared_error: 0.5408 - val_loss: 0.5510 - val_mean_squared_error: 0.5510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5340 - mean_squared_error: 0.5340 - val_loss: 0.5485 - val_mean_squared_error: 0.5485\n",
      "Epoch 289/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5294 - mean_squared_error: 0.5294 - val_loss: 0.5389 - val_mean_squared_error: 0.5389\n",
      "Epoch 290/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5225 - mean_squared_error: 0.5225 - val_loss: 0.5313 - val_mean_squared_error: 0.5313\n",
      "Epoch 291/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5178 - mean_squared_error: 0.5178 - val_loss: 0.5269 - val_mean_squared_error: 0.5269\n",
      "Epoch 292/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5116 - mean_squared_error: 0.5116 - val_loss: 0.5212 - val_mean_squared_error: 0.5212\n",
      "Epoch 293/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.5070 - mean_squared_error: 0.5070 - val_loss: 0.5145 - val_mean_squared_error: 0.5145\n",
      "Epoch 294/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.5006 - mean_squared_error: 0.5006 - val_loss: 0.5127 - val_mean_squared_error: 0.5127\n",
      "Epoch 295/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4956 - mean_squared_error: 0.4956 - val_loss: 0.5092 - val_mean_squared_error: 0.5092\n",
      "Epoch 296/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4935 - mean_squared_error: 0.4935 - val_loss: 0.5024 - val_mean_squared_error: 0.5024\n",
      "Epoch 297/500\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 0.4879 - mean_squared_error: 0.4879 - val_loss: 0.4956 - val_mean_squared_error: 0.4956\n",
      "Epoch 298/500\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 0.4853 - mean_squared_error: 0.4853 - val_loss: 0.4916 - val_mean_squared_error: 0.4916\n",
      "Epoch 299/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4805 - mean_squared_error: 0.4805 - val_loss: 0.4902 - val_mean_squared_error: 0.4902\n",
      "Epoch 300/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4781 - mean_squared_error: 0.4781 - val_loss: 0.4866 - val_mean_squared_error: 0.4866\n",
      "Epoch 301/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4773 - mean_squared_error: 0.4773 - val_loss: 0.4865 - val_mean_squared_error: 0.4865\n",
      "Epoch 302/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4738 - mean_squared_error: 0.4738 - val_loss: 0.4803 - val_mean_squared_error: 0.4803\n",
      "Epoch 303/500\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 0.4700 - mean_squared_error: 0.4700 - val_loss: 0.4787 - val_mean_squared_error: 0.4787\n",
      "Epoch 304/500\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 0.4675 - mean_squared_error: 0.4675 - val_loss: 0.4864 - val_mean_squared_error: 0.4864\n",
      "Epoch 305/500\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 0.4677 - mean_squared_error: 0.4677 - val_loss: 0.4758 - val_mean_squared_error: 0.4758\n",
      "Epoch 306/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4634 - mean_squared_error: 0.4634 - val_loss: 0.4715 - val_mean_squared_error: 0.4715\n",
      "Epoch 307/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4593 - mean_squared_error: 0.4593 - val_loss: 0.4705 - val_mean_squared_error: 0.4705\n",
      "Epoch 308/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4577 - mean_squared_error: 0.4577 - val_loss: 0.4681 - val_mean_squared_error: 0.4681\n",
      "Epoch 309/500\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 0.4544 - mean_squared_error: 0.4544 - val_loss: 0.4648 - val_mean_squared_error: 0.4648\n",
      "Epoch 310/500\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 0.4537 - mean_squared_error: 0.4537 - val_loss: 0.4607 - val_mean_squared_error: 0.4607\n",
      "Epoch 311/500\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 0.4506 - mean_squared_error: 0.4506 - val_loss: 0.4585 - val_mean_squared_error: 0.4585\n",
      "Epoch 312/500\n",
      "148/148 [==============================] - 1s 10ms/step - loss: 0.4505 - mean_squared_error: 0.4505 - val_loss: 0.4546 - val_mean_squared_error: 0.4546\n",
      "Epoch 313/500\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.4479 - mean_squared_error: 0.4479 - val_loss: 0.4567 - val_mean_squared_error: 0.4567\n",
      "Epoch 314/500\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.4452 - mean_squared_error: 0.4452 - val_loss: 0.4562 - val_mean_squared_error: 0.4562\n",
      "Epoch 315/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4446 - mean_squared_error: 0.4446 - val_loss: 0.4494 - val_mean_squared_error: 0.4494\n",
      "Epoch 316/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4430 - mean_squared_error: 0.4430 - val_loss: 0.4504 - val_mean_squared_error: 0.4504\n",
      "Epoch 317/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4401 - mean_squared_error: 0.4401 - val_loss: 0.4459 - val_mean_squared_error: 0.4459\n",
      "Epoch 318/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4377 - mean_squared_error: 0.4377 - val_loss: 0.4440 - val_mean_squared_error: 0.4440\n",
      "Epoch 319/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4376 - mean_squared_error: 0.4376 - val_loss: 0.4468 - val_mean_squared_error: 0.4468\n",
      "Epoch 320/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4355 - mean_squared_error: 0.4355 - val_loss: 0.4433 - val_mean_squared_error: 0.4433\n",
      "Epoch 321/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4350 - mean_squared_error: 0.4350 - val_loss: 0.4452 - val_mean_squared_error: 0.4452\n",
      "Epoch 322/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4328 - mean_squared_error: 0.4328 - val_loss: 0.4380 - val_mean_squared_error: 0.4380\n",
      "Epoch 323/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4319 - mean_squared_error: 0.4319 - val_loss: 0.4377 - val_mean_squared_error: 0.4377\n",
      "Epoch 324/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4307 - mean_squared_error: 0.4307 - val_loss: 0.4366 - val_mean_squared_error: 0.4366\n",
      "Epoch 325/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4295 - mean_squared_error: 0.4295 - val_loss: 0.4347 - val_mean_squared_error: 0.4347\n",
      "Epoch 326/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4270 - mean_squared_error: 0.4270 - val_loss: 0.4321 - val_mean_squared_error: 0.4321\n",
      "Epoch 327/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4262 - mean_squared_error: 0.4262 - val_loss: 0.4302 - val_mean_squared_error: 0.4302\n",
      "Epoch 328/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4243 - mean_squared_error: 0.4243 - val_loss: 0.4282 - val_mean_squared_error: 0.4282\n",
      "Epoch 329/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4229 - mean_squared_error: 0.4229 - val_loss: 0.4282 - val_mean_squared_error: 0.4282\n",
      "Epoch 330/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4221 - mean_squared_error: 0.4221 - val_loss: 0.4272 - val_mean_squared_error: 0.4272\n",
      "Epoch 331/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4203 - mean_squared_error: 0.4203 - val_loss: 0.4251 - val_mean_squared_error: 0.4251\n",
      "Epoch 332/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4209 - mean_squared_error: 0.4209 - val_loss: 0.4227 - val_mean_squared_error: 0.4227\n",
      "Epoch 333/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4185 - mean_squared_error: 0.4185 - val_loss: 0.4237 - val_mean_squared_error: 0.4237\n",
      "Epoch 334/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4190 - mean_squared_error: 0.4190 - val_loss: 0.4192 - val_mean_squared_error: 0.4192\n",
      "Epoch 335/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4166 - mean_squared_error: 0.4166 - val_loss: 0.4191 - val_mean_squared_error: 0.4191\n",
      "Epoch 336/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4151 - mean_squared_error: 0.4151 - val_loss: 0.4186 - val_mean_squared_error: 0.4186\n",
      "Epoch 337/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4146 - mean_squared_error: 0.4146 - val_loss: 0.4163 - val_mean_squared_error: 0.4163\n",
      "Epoch 338/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4134 - mean_squared_error: 0.4134 - val_loss: 0.4173 - val_mean_squared_error: 0.4173\n",
      "Epoch 339/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4106 - mean_squared_error: 0.4106 - val_loss: 0.4164 - val_mean_squared_error: 0.4164\n",
      "Epoch 340/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4127 - mean_squared_error: 0.4127 - val_loss: 0.4153 - val_mean_squared_error: 0.4153\n",
      "Epoch 341/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4103 - mean_squared_error: 0.4103 - val_loss: 0.4149 - val_mean_squared_error: 0.4149\n",
      "Epoch 342/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4091 - mean_squared_error: 0.4091 - val_loss: 0.4125 - val_mean_squared_error: 0.4125\n",
      "Epoch 343/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4102 - mean_squared_error: 0.4102 - val_loss: 0.4160 - val_mean_squared_error: 0.4160\n",
      "Epoch 344/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4084 - mean_squared_error: 0.4084 - val_loss: 0.4089 - val_mean_squared_error: 0.4089\n",
      "Epoch 345/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4073 - mean_squared_error: 0.4073 - val_loss: 0.4105 - val_mean_squared_error: 0.4105\n",
      "Epoch 346/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4066 - mean_squared_error: 0.4066 - val_loss: 0.4089 - val_mean_squared_error: 0.4089\n",
      "Epoch 347/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4055 - mean_squared_error: 0.4055 - val_loss: 0.4085 - val_mean_squared_error: 0.4085\n",
      "Epoch 348/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4041 - mean_squared_error: 0.4041 - val_loss: 0.4045 - val_mean_squared_error: 0.4045\n",
      "Epoch 349/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4040 - mean_squared_error: 0.4040 - val_loss: 0.4050 - val_mean_squared_error: 0.4050\n",
      "Epoch 350/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4024 - mean_squared_error: 0.4024 - val_loss: 0.4047 - val_mean_squared_error: 0.4047\n",
      "Epoch 351/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4024 - mean_squared_error: 0.4024 - val_loss: 0.4056 - val_mean_squared_error: 0.4056\n",
      "Epoch 352/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.4011 - mean_squared_error: 0.4011 - val_loss: 0.4052 - val_mean_squared_error: 0.4052\n",
      "Epoch 353/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4003 - mean_squared_error: 0.4003 - val_loss: 0.4040 - val_mean_squared_error: 0.4040\n",
      "Epoch 354/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.4008 - mean_squared_error: 0.4008 - val_loss: 0.4054 - val_mean_squared_error: 0.4054\n",
      "Epoch 355/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3980 - mean_squared_error: 0.3980 - val_loss: 0.4062 - val_mean_squared_error: 0.4062\n",
      "Epoch 356/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3991 - mean_squared_error: 0.3991 - val_loss: 0.4003 - val_mean_squared_error: 0.4003\n",
      "Epoch 357/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3970 - mean_squared_error: 0.3970 - val_loss: 0.4015 - val_mean_squared_error: 0.4015\n",
      "Epoch 358/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3974 - mean_squared_error: 0.3974 - val_loss: 0.3992 - val_mean_squared_error: 0.3992\n",
      "Epoch 359/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3963 - mean_squared_error: 0.3963 - val_loss: 0.3966 - val_mean_squared_error: 0.3966\n",
      "Epoch 360/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3970 - mean_squared_error: 0.3970 - val_loss: 0.3974 - val_mean_squared_error: 0.3974\n",
      "Epoch 361/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3945 - mean_squared_error: 0.3945 - val_loss: 0.3957 - val_mean_squared_error: 0.3957\n",
      "Epoch 362/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3943 - mean_squared_error: 0.3943 - val_loss: 0.3988 - val_mean_squared_error: 0.3988\n",
      "Epoch 363/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3938 - mean_squared_error: 0.3938 - val_loss: 0.3948 - val_mean_squared_error: 0.3948\n",
      "Epoch 364/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3923 - mean_squared_error: 0.3923 - val_loss: 0.3951 - val_mean_squared_error: 0.3951\n",
      "Epoch 365/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3907 - mean_squared_error: 0.3907 - val_loss: 0.4015 - val_mean_squared_error: 0.4015\n",
      "Epoch 366/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3923 - mean_squared_error: 0.3923 - val_loss: 0.3956 - val_mean_squared_error: 0.3956\n",
      "Epoch 367/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3906 - mean_squared_error: 0.3906 - val_loss: 0.3917 - val_mean_squared_error: 0.3917\n",
      "Epoch 368/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3903 - mean_squared_error: 0.3903 - val_loss: 0.3949 - val_mean_squared_error: 0.3949\n",
      "Epoch 369/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3908 - mean_squared_error: 0.3908 - val_loss: 0.3923 - val_mean_squared_error: 0.3923\n",
      "Epoch 370/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3891 - mean_squared_error: 0.3891 - val_loss: 0.3916 - val_mean_squared_error: 0.3916\n",
      "Epoch 371/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3879 - mean_squared_error: 0.3879 - val_loss: 0.3894 - val_mean_squared_error: 0.3894\n",
      "Epoch 372/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3875 - mean_squared_error: 0.3875 - val_loss: 0.3876 - val_mean_squared_error: 0.3876\n",
      "Epoch 373/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3875 - mean_squared_error: 0.3875 - val_loss: 0.3881 - val_mean_squared_error: 0.3881\n",
      "Epoch 374/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3873 - mean_squared_error: 0.3873 - val_loss: 0.3857 - val_mean_squared_error: 0.3857\n",
      "Epoch 375/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3857 - mean_squared_error: 0.3857 - val_loss: 0.3864 - val_mean_squared_error: 0.3864\n",
      "Epoch 376/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3866 - mean_squared_error: 0.3866 - val_loss: 0.3876 - val_mean_squared_error: 0.3876\n",
      "Epoch 377/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3837 - mean_squared_error: 0.3837 - val_loss: 0.3871 - val_mean_squared_error: 0.3871\n",
      "Epoch 378/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3834 - mean_squared_error: 0.3834 - val_loss: 0.3845 - val_mean_squared_error: 0.3845\n",
      "Epoch 379/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3819 - mean_squared_error: 0.3819 - val_loss: 0.3851 - val_mean_squared_error: 0.3851\n",
      "Epoch 380/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3822 - mean_squared_error: 0.3822 - val_loss: 0.3818 - val_mean_squared_error: 0.3818\n",
      "Epoch 381/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3816 - mean_squared_error: 0.3816 - val_loss: 0.3834 - val_mean_squared_error: 0.3834\n",
      "Epoch 382/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3814 - mean_squared_error: 0.3814 - val_loss: 0.3810 - val_mean_squared_error: 0.3810\n",
      "Epoch 383/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3811 - mean_squared_error: 0.3811 - val_loss: 0.3824 - val_mean_squared_error: 0.3824\n",
      "Epoch 384/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3793 - mean_squared_error: 0.3793 - val_loss: 0.3886 - val_mean_squared_error: 0.3886\n",
      "Epoch 385/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3809 - mean_squared_error: 0.3809 - val_loss: 0.3847 - val_mean_squared_error: 0.3847\n",
      "Epoch 386/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3783 - mean_squared_error: 0.3783 - val_loss: 0.3791 - val_mean_squared_error: 0.3791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 387/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3794 - mean_squared_error: 0.3794 - val_loss: 0.3780 - val_mean_squared_error: 0.3780\n",
      "Epoch 388/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3766 - mean_squared_error: 0.3766 - val_loss: 0.3773 - val_mean_squared_error: 0.3773\n",
      "Epoch 389/500\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.3763 - mean_squared_error: 0.3763 - val_loss: 0.3753 - val_mean_squared_error: 0.3753\n",
      "Epoch 390/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3754 - mean_squared_error: 0.3754 - val_loss: 0.3768 - val_mean_squared_error: 0.3768\n",
      "Epoch 391/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3745 - mean_squared_error: 0.3745 - val_loss: 0.3770 - val_mean_squared_error: 0.3770\n",
      "Epoch 392/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3753 - mean_squared_error: 0.3753 - val_loss: 0.3755 - val_mean_squared_error: 0.3755\n",
      "Epoch 393/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3741 - mean_squared_error: 0.3741 - val_loss: 0.3744 - val_mean_squared_error: 0.3744\n",
      "Epoch 394/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3720 - mean_squared_error: 0.3720 - val_loss: 0.3769 - val_mean_squared_error: 0.3769\n",
      "Epoch 395/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3730 - mean_squared_error: 0.3730 - val_loss: 0.3728 - val_mean_squared_error: 0.3728\n",
      "Epoch 396/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3727 - mean_squared_error: 0.3727 - val_loss: 0.3759 - val_mean_squared_error: 0.3759\n",
      "Epoch 397/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3720 - mean_squared_error: 0.3720 - val_loss: 0.3717 - val_mean_squared_error: 0.3717\n",
      "Epoch 398/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3710 - mean_squared_error: 0.3710 - val_loss: 0.3733 - val_mean_squared_error: 0.3733\n",
      "Epoch 399/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3700 - mean_squared_error: 0.3700 - val_loss: 0.3736 - val_mean_squared_error: 0.3736\n",
      "Epoch 400/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3709 - mean_squared_error: 0.3709 - val_loss: 0.3719 - val_mean_squared_error: 0.3719\n",
      "Epoch 401/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3691 - mean_squared_error: 0.3691 - val_loss: 0.3764 - val_mean_squared_error: 0.3764\n",
      "Epoch 402/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3701 - mean_squared_error: 0.3701 - val_loss: 0.3712 - val_mean_squared_error: 0.3712\n",
      "Epoch 403/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3700 - mean_squared_error: 0.3700 - val_loss: 0.3695 - val_mean_squared_error: 0.3695\n",
      "Epoch 404/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3670 - mean_squared_error: 0.3670 - val_loss: 0.3705 - val_mean_squared_error: 0.3705\n",
      "Epoch 405/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3674 - mean_squared_error: 0.3674 - val_loss: 0.3674 - val_mean_squared_error: 0.3674\n",
      "Epoch 406/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3671 - mean_squared_error: 0.3671 - val_loss: 0.3697 - val_mean_squared_error: 0.3697\n",
      "Epoch 407/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3656 - mean_squared_error: 0.3656 - val_loss: 0.3661 - val_mean_squared_error: 0.3661\n",
      "Epoch 408/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3649 - mean_squared_error: 0.3649 - val_loss: 0.3652 - val_mean_squared_error: 0.3652\n",
      "Epoch 409/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3645 - mean_squared_error: 0.3645 - val_loss: 0.3647 - val_mean_squared_error: 0.3647\n",
      "Epoch 410/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3640 - mean_squared_error: 0.3640 - val_loss: 0.3637 - val_mean_squared_error: 0.3637\n",
      "Epoch 411/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3640 - mean_squared_error: 0.3640 - val_loss: 0.3654 - val_mean_squared_error: 0.3654\n",
      "Epoch 412/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3620 - mean_squared_error: 0.3620 - val_loss: 0.3687 - val_mean_squared_error: 0.3687\n",
      "Epoch 413/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3626 - mean_squared_error: 0.3626 - val_loss: 0.3644 - val_mean_squared_error: 0.3644\n",
      "Epoch 414/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3628 - mean_squared_error: 0.3628 - val_loss: 0.3632 - val_mean_squared_error: 0.3632\n",
      "Epoch 415/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3629 - mean_squared_error: 0.3629 - val_loss: 0.3644 - val_mean_squared_error: 0.3644\n",
      "Epoch 416/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3613 - mean_squared_error: 0.3613 - val_loss: 0.3607 - val_mean_squared_error: 0.3607\n",
      "Epoch 417/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3606 - mean_squared_error: 0.3606 - val_loss: 0.3616 - val_mean_squared_error: 0.3616\n",
      "Epoch 418/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3589 - mean_squared_error: 0.3589 - val_loss: 0.3662 - val_mean_squared_error: 0.3662\n",
      "Epoch 419/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3596 - mean_squared_error: 0.3596 - val_loss: 0.3645 - val_mean_squared_error: 0.3645\n",
      "Epoch 420/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3601 - mean_squared_error: 0.3601 - val_loss: 0.3643 - val_mean_squared_error: 0.3643\n",
      "Epoch 421/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3596 - mean_squared_error: 0.3596 - val_loss: 0.3603 - val_mean_squared_error: 0.3603\n",
      "Epoch 422/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3584 - mean_squared_error: 0.3584 - val_loss: 0.3631 - val_mean_squared_error: 0.3631\n",
      "Epoch 423/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3577 - mean_squared_error: 0.3577 - val_loss: 0.3597 - val_mean_squared_error: 0.3597\n",
      "Epoch 424/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3593 - mean_squared_error: 0.3593 - val_loss: 0.3584 - val_mean_squared_error: 0.3584\n",
      "Epoch 425/500\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 0.3571 - mean_squared_error: 0.3571 - val_loss: 0.3617 - val_mean_squared_error: 0.3617\n",
      "Epoch 426/500\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 0.3580 - mean_squared_error: 0.3580 - val_loss: 0.3591 - val_mean_squared_error: 0.3591\n",
      "Epoch 427/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3568 - mean_squared_error: 0.3568 - val_loss: 0.3587 - val_mean_squared_error: 0.3587\n",
      "Epoch 428/500\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 0.3559 - mean_squared_error: 0.3559 - val_loss: 0.3581 - val_mean_squared_error: 0.3581\n",
      "Epoch 429/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3568 - mean_squared_error: 0.3568 - val_loss: 0.3587 - val_mean_squared_error: 0.3587\n",
      "Epoch 430/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3554 - mean_squared_error: 0.3554 - val_loss: 0.3575 - val_mean_squared_error: 0.3575\n",
      "Epoch 431/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3549 - mean_squared_error: 0.3549 - val_loss: 0.3556 - val_mean_squared_error: 0.3556\n",
      "Epoch 432/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3549 - mean_squared_error: 0.3549 - val_loss: 0.3599 - val_mean_squared_error: 0.3599\n",
      "Epoch 433/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3540 - mean_squared_error: 0.3540 - val_loss: 0.3583 - val_mean_squared_error: 0.3583\n",
      "Epoch 434/500\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 0.3543 - mean_squared_error: 0.3543 - val_loss: 0.3565 - val_mean_squared_error: 0.3565\n",
      "Epoch 435/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3543 - mean_squared_error: 0.3543 - val_loss: 0.3592 - val_mean_squared_error: 0.3592\n",
      "Epoch 436/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3533 - mean_squared_error: 0.3533 - val_loss: 0.3537 - val_mean_squared_error: 0.3537\n",
      "Epoch 437/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3520 - mean_squared_error: 0.3520 - val_loss: 0.3622 - val_mean_squared_error: 0.3622\n",
      "Epoch 438/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3527 - mean_squared_error: 0.3527 - val_loss: 0.3548 - val_mean_squared_error: 0.3548\n",
      "Epoch 439/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3531 - mean_squared_error: 0.3531 - val_loss: 0.3526 - val_mean_squared_error: 0.3526\n",
      "Epoch 440/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3512 - mean_squared_error: 0.3512 - val_loss: 0.3542 - val_mean_squared_error: 0.3542\n",
      "Epoch 441/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3503 - mean_squared_error: 0.3503 - val_loss: 0.3587 - val_mean_squared_error: 0.3587\n",
      "Epoch 442/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3514 - mean_squared_error: 0.3514 - val_loss: 0.3510 - val_mean_squared_error: 0.3510\n",
      "Epoch 443/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3500 - mean_squared_error: 0.3500 - val_loss: 0.3524 - val_mean_squared_error: 0.3524\n",
      "Epoch 444/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3500 - mean_squared_error: 0.3500 - val_loss: 0.3524 - val_mean_squared_error: 0.3524\n",
      "Epoch 445/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3500 - mean_squared_error: 0.3500 - val_loss: 0.3501 - val_mean_squared_error: 0.3501\n",
      "Epoch 446/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3505 - mean_squared_error: 0.3505 - val_loss: 0.3502 - val_mean_squared_error: 0.3502\n",
      "Epoch 447/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3495 - mean_squared_error: 0.3495 - val_loss: 0.3548 - val_mean_squared_error: 0.3548\n",
      "Epoch 448/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3494 - mean_squared_error: 0.3494 - val_loss: 0.3502 - val_mean_squared_error: 0.3502\n",
      "Epoch 449/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3482 - mean_squared_error: 0.3482 - val_loss: 0.3525 - val_mean_squared_error: 0.3525\n",
      "Epoch 450/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3490 - mean_squared_error: 0.3490 - val_loss: 0.3487 - val_mean_squared_error: 0.3487\n",
      "Epoch 451/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3476 - mean_squared_error: 0.3476 - val_loss: 0.3498 - val_mean_squared_error: 0.3498\n",
      "Epoch 452/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3489 - mean_squared_error: 0.3489 - val_loss: 0.3524 - val_mean_squared_error: 0.3524\n",
      "Epoch 453/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3477 - mean_squared_error: 0.3477 - val_loss: 0.3487 - val_mean_squared_error: 0.3487\n",
      "Epoch 454/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3465 - mean_squared_error: 0.3465 - val_loss: 0.3487 - val_mean_squared_error: 0.3487\n",
      "Epoch 455/500\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 0.3470 - mean_squared_error: 0.3470 - val_loss: 0.3482 - val_mean_squared_error: 0.3482\n",
      "Epoch 456/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3474 - mean_squared_error: 0.3474 - val_loss: 0.3494 - val_mean_squared_error: 0.3494\n",
      "Epoch 457/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3452 - mean_squared_error: 0.3452 - val_loss: 0.3459 - val_mean_squared_error: 0.3459\n",
      "Epoch 458/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3462 - mean_squared_error: 0.3462 - val_loss: 0.3481 - val_mean_squared_error: 0.3481\n",
      "Epoch 459/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3459 - mean_squared_error: 0.3459 - val_loss: 0.3466 - val_mean_squared_error: 0.3466\n",
      "Epoch 460/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3463 - mean_squared_error: 0.3463 - val_loss: 0.3454 - val_mean_squared_error: 0.3454\n",
      "Epoch 461/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3451 - mean_squared_error: 0.3451 - val_loss: 0.3450 - val_mean_squared_error: 0.3450\n",
      "Epoch 462/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3450 - mean_squared_error: 0.3450 - val_loss: 0.3464 - val_mean_squared_error: 0.3464\n",
      "Epoch 463/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3450 - mean_squared_error: 0.3450 - val_loss: 0.3493 - val_mean_squared_error: 0.3493\n",
      "Epoch 464/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3444 - mean_squared_error: 0.3444 - val_loss: 0.3464 - val_mean_squared_error: 0.3464\n",
      "Epoch 465/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3443 - mean_squared_error: 0.3443 - val_loss: 0.3449 - val_mean_squared_error: 0.3449\n",
      "Epoch 466/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3433 - mean_squared_error: 0.3433 - val_loss: 0.3448 - val_mean_squared_error: 0.3448\n",
      "Epoch 467/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3434 - mean_squared_error: 0.3434 - val_loss: 0.3443 - val_mean_squared_error: 0.3443\n",
      "Epoch 468/500\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 0.3442 - mean_squared_error: 0.3442 - val_loss: 0.3446 - val_mean_squared_error: 0.3446\n",
      "Epoch 469/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3423 - mean_squared_error: 0.3423 - val_loss: 0.3490 - val_mean_squared_error: 0.3490\n",
      "Epoch 470/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3422 - mean_squared_error: 0.3422 - val_loss: 0.3473 - val_mean_squared_error: 0.3473\n",
      "Epoch 471/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3423 - mean_squared_error: 0.3423 - val_loss: 0.3426 - val_mean_squared_error: 0.3426\n",
      "Epoch 472/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3417 - mean_squared_error: 0.3417 - val_loss: 0.3436 - val_mean_squared_error: 0.3436\n",
      "Epoch 473/500\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 0.3414 - mean_squared_error: 0.3414 - val_loss: 0.3464 - val_mean_squared_error: 0.3464\n",
      "Epoch 474/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3417 - mean_squared_error: 0.3417 - val_loss: 0.3534 - val_mean_squared_error: 0.3534\n",
      "Epoch 475/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3414 - mean_squared_error: 0.3414 - val_loss: 0.3454 - val_mean_squared_error: 0.3454\n",
      "Epoch 476/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3412 - mean_squared_error: 0.3412 - val_loss: 0.3438 - val_mean_squared_error: 0.3438\n",
      "Epoch 477/500\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 0.3403 - mean_squared_error: 0.3403 - val_loss: 0.3483 - val_mean_squared_error: 0.3483\n",
      "Epoch 478/500\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 0.3404 - mean_squared_error: 0.3404 - val_loss: 0.3434 - val_mean_squared_error: 0.3434\n",
      "Epoch 479/500\n",
      "148/148 [==============================] - 1s 7ms/step - loss: 0.3415 - mean_squared_error: 0.3415 - val_loss: 0.3421 - val_mean_squared_error: 0.3421\n",
      "Epoch 480/500\n",
      "148/148 [==============================] - 1s 9ms/step - loss: 0.3398 - mean_squared_error: 0.3398 - val_loss: 0.3468 - val_mean_squared_error: 0.3468\n",
      "Epoch 481/500\n",
      "148/148 [==============================] - 1s 4ms/step - loss: 0.3410 - mean_squared_error: 0.3410 - val_loss: 0.3459 - val_mean_squared_error: 0.3459\n",
      "Epoch 482/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3401 - mean_squared_error: 0.3401 - val_loss: 0.3413 - val_mean_squared_error: 0.3413\n",
      "Epoch 483/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3391 - mean_squared_error: 0.3391 - val_loss: 0.3425 - val_mean_squared_error: 0.3425\n",
      "Epoch 484/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3395 - mean_squared_error: 0.3395 - val_loss: 0.3426 - val_mean_squared_error: 0.3426\n",
      "Epoch 485/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3390 - mean_squared_error: 0.3390 - val_loss: 0.3424 - val_mean_squared_error: 0.3424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 486/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3377 - mean_squared_error: 0.3377 - val_loss: 0.3399 - val_mean_squared_error: 0.3399\n",
      "Epoch 487/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3401 - mean_squared_error: 0.3401 - val_loss: 0.3395 - val_mean_squared_error: 0.3395\n",
      "Epoch 488/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3377 - mean_squared_error: 0.3377 - val_loss: 0.3436 - val_mean_squared_error: 0.3436\n",
      "Epoch 489/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3385 - mean_squared_error: 0.3385 - val_loss: 0.3404 - val_mean_squared_error: 0.3404\n",
      "Epoch 490/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3371 - mean_squared_error: 0.3371 - val_loss: 0.3406 - val_mean_squared_error: 0.3406\n",
      "Epoch 491/500\n",
      "148/148 [==============================] - 1s 6ms/step - loss: 0.3379 - mean_squared_error: 0.3379 - val_loss: 0.3396 - val_mean_squared_error: 0.3396\n",
      "Epoch 492/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3381 - mean_squared_error: 0.3381 - val_loss: 0.3428 - val_mean_squared_error: 0.3428\n",
      "Epoch 493/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3372 - mean_squared_error: 0.3372 - val_loss: 0.3373 - val_mean_squared_error: 0.3373\n",
      "Epoch 494/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3371 - mean_squared_error: 0.3371 - val_loss: 0.3412 - val_mean_squared_error: 0.3412\n",
      "Epoch 495/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3378 - mean_squared_error: 0.3378 - val_loss: 0.3390 - val_mean_squared_error: 0.3390\n",
      "Epoch 496/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3366 - mean_squared_error: 0.3366 - val_loss: 0.3402 - val_mean_squared_error: 0.3402\n",
      "Epoch 497/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3358 - mean_squared_error: 0.3358 - val_loss: 0.3395 - val_mean_squared_error: 0.3395\n",
      "Epoch 498/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3355 - mean_squared_error: 0.3355 - val_loss: 0.3381 - val_mean_squared_error: 0.3381\n",
      "Epoch 499/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3358 - mean_squared_error: 0.3358 - val_loss: 0.3399 - val_mean_squared_error: 0.3399\n",
      "Epoch 500/500\n",
      "148/148 [==============================] - 1s 5ms/step - loss: 0.3357 - mean_squared_error: 0.3357 - val_loss: 0.3381 - val_mean_squared_error: 0.3381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a927b3b1f0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=10, activation='tanh'))\n",
    "model.add(Dense(8,activation='sigmoid'))\n",
    "model.add(Dense(1,activation=None))\n",
    "model.compile(loss='mean_squared_error', optimizer='adamax', metrics=['mean_squared_error'])\n",
    "model.fit(x_train,y_train, validation_split=0.3, epochs=500, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85ae0fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329/329 [==============================] - 1s 4ms/step - loss: 0.3349 - mean_squared_error: 0.3349\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3349042236804962, 0.3349042236804962]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f08eb750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 2s 14ms/step - loss: 0.3983 - mean_squared_error: 0.3983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3983059525489807, 0.3983059525489807]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f886fd28",
   "metadata": {},
   "source": [
    "Model 4 has minimum mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268ea2b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
